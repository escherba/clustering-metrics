

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>clustering_metrics.metrics &mdash; Clustering-Metrics 0.0.2 documentation</title>
  

  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  

  

  
    <link rel="top" title="Clustering-Metrics 0.0.2 documentation" href="../../index.html"/>
        <link rel="up" title="Module code" href="../index.html"/> 

  
  <script src="../../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../../index.html" class="icon icon-home"> Clustering-Metrics
          

          
          </a>

          
            
            
              <div class="version">
                0.0.2
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
                <ul>
<li class="toctree-l1"><a class="reference internal" href="../../clustering_metrics.html">clustering_metrics package</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="../../index.html">Clustering-Metrics</a>
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          





<div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../../index.html">Docs</a> &raquo;</li>
      
          <li><a href="../index.html">Module code</a> &raquo;</li>
      
    <li>clustering_metrics.metrics</li>
      <li class="wy-breadcrumbs-aside">
        
          
        
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for clustering_metrics.metrics</h1><div class="highlight"><pre>
<span></span><span class="c1"># -*- coding: utf-8 -*-</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">math</span> <span class="k">import</span> <span class="n">log</span><span class="p">,</span> <span class="n">sqrt</span><span class="p">,</span> <span class="n">copysign</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="k">import</span> <span class="n">Set</span><span class="p">,</span> <span class="n">namedtuple</span>
<span class="kn">from</span> <span class="nn">pymaptools.containers</span> <span class="k">import</span> <span class="n">CrossTab</span><span class="p">,</span> <span class="n">OrderedCrossTab</span>
<span class="kn">from</span> <span class="nn">pymaptools.iter</span> <span class="k">import</span> <span class="n">iter_items</span><span class="p">,</span> <span class="n">isiterable</span>
<span class="kn">from</span> <span class="nn">pymaptools.sample</span> <span class="k">import</span> <span class="n">randround</span>
<span class="kn">from</span> <span class="nn">clustering_metrics.utils</span> <span class="k">import</span> <span class="n">_div</span><span class="p">,</span> <span class="n">_log</span>
<span class="kn">from</span> <span class="nn">clustering_metrics.entropy</span> <span class="k">import</span> <span class="n">fentropy</span><span class="p">,</span> <span class="n">fnum_pairs</span><span class="p">,</span> <span class="n">fsum_pairs</span><span class="p">,</span> \
    <span class="n">emi_from_margins</span><span class="p">,</span> <span class="n">assignment_cost</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="k">import</span> <span class="n">fisher_exact</span>


<div class="viewcode-block" id="jaccard_similarity"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.jaccard_similarity">[docs]</a><span class="k">def</span> <span class="nf">jaccard_similarity</span><span class="p">(</span><span class="n">iterable1</span><span class="p">,</span> <span class="n">iterable2</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Jaccard similarity between two sets</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    iterable1 : collections.Iterable</span>
<span class="sd">        first bag of items (order irrelevant)</span>

<span class="sd">    iterable2 : collections.Iterable</span>
<span class="sd">        second bag of items (order irrelevant)</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>

<span class="sd">    jaccard_similarity : float</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">t</span> <span class="o">=</span> <span class="n">ConfusionMatrix2</span><span class="o">.</span><span class="n">from_sets</span><span class="p">(</span><span class="n">iterable1</span><span class="p">,</span> <span class="n">iterable2</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">t</span><span class="o">.</span><span class="n">jaccard_coeff</span><span class="p">()</span></div>


<div class="viewcode-block" id="ratio2weights"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.ratio2weights">[docs]</a><span class="k">def</span> <span class="nf">ratio2weights</span><span class="p">(</span><span class="n">ratio</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Numerically accurate conversion of ratio of two weights to weights</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">ratio</span> <span class="o">&lt;=</span> <span class="mf">1.0</span><span class="p">:</span>
        <span class="n">lweight</span> <span class="o">=</span> <span class="n">ratio</span> <span class="o">/</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">+</span> <span class="n">ratio</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">lweight</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">+</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="n">ratio</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">lweight</span><span class="p">,</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">lweight</span></div>


<div class="viewcode-block" id="geometric_mean"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.geometric_mean">[docs]</a><span class="k">def</span> <span class="nf">geometric_mean</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Geometric mean of two numbers. Always returns a float</span>

<span class="sd">    Although geometric mean is defined for negative numbers, Scipy function</span>
<span class="sd">    doesn&#39;t allow it. Hence this function</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">prod</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="n">y</span>
    <span class="k">if</span> <span class="n">prod</span> <span class="o">&lt;</span> <span class="mf">0.0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;x and y have different signs&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">copysign</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> <span class="o">*</span> <span class="n">sqrt</span><span class="p">(</span><span class="n">prod</span><span class="p">)</span></div>


<div class="viewcode-block" id="geometric_mean_weighted"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.geometric_mean_weighted">[docs]</a><span class="k">def</span> <span class="nf">geometric_mean_weighted</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">ratio</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Geometric mean of two numbers with a weight ratio. Returns a float</span>

<span class="sd">    ::</span>

<span class="sd">        &gt;&gt;&gt; geometric_mean_weighted(1, 4, ratio=1.0)</span>
<span class="sd">        2.0</span>
<span class="sd">        &gt;&gt;&gt; geometric_mean_weighted(1, 4, ratio=0.0)</span>
<span class="sd">        1.0</span>
<span class="sd">        &gt;&gt;&gt; geometric_mean_weighted(1, 4, ratio=float(&#39;inf&#39;))</span>
<span class="sd">        4.0</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">lweight</span><span class="p">,</span> <span class="n">rweight</span> <span class="o">=</span> <span class="n">ratio2weights</span><span class="p">(</span><span class="n">ratio</span><span class="p">)</span>
    <span class="n">lsign</span> <span class="o">=</span> <span class="n">copysign</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
    <span class="n">rsign</span> <span class="o">=</span> <span class="n">copysign</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">lsign</span> <span class="o">!=</span> <span class="n">rsign</span> <span class="ow">and</span> <span class="n">x</span> <span class="o">!=</span> <span class="n">y</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;x and y have different signs&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">lsign</span> <span class="o">*</span> <span class="p">(</span><span class="nb">abs</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">**</span> <span class="n">rweight</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="nb">abs</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="o">**</span> <span class="n">lweight</span><span class="p">)</span></div>


<div class="viewcode-block" id="unitsq_sigmoid"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.unitsq_sigmoid">[docs]</a><span class="k">def</span> <span class="nf">unitsq_sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Unit square sigmoid (for transforming P-like scales)</span>

<span class="sd">    ::</span>

<span class="sd">        &gt;&gt;&gt; round(unitsq_sigmoid(0.1), 4)</span>
<span class="sd">        0.25</span>
<span class="sd">        &gt;&gt;&gt; round(unitsq_sigmoid(0.9), 4)</span>
<span class="sd">        0.75</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">x</span> <span class="o">**</span> <span class="n">s</span>
    <span class="n">b</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">x</span><span class="p">)</span> <span class="o">**</span> <span class="n">s</span>
    <span class="k">return</span> <span class="n">a</span> <span class="o">/</span> <span class="p">(</span><span class="n">a</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span></div>


<div class="viewcode-block" id="harmonic_mean"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.harmonic_mean">[docs]</a><span class="k">def</span> <span class="nf">harmonic_mean</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Harmonic mean of two numbers. Always returns a float</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="nb">float</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">if</span> <span class="n">x</span> <span class="o">==</span> <span class="n">y</span> <span class="k">else</span> <span class="mf">2.0</span> <span class="o">*</span> <span class="p">(</span><span class="n">x</span> <span class="o">*</span> <span class="n">y</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="n">y</span><span class="p">)</span></div>


<div class="viewcode-block" id="harmonic_mean_weighted"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.harmonic_mean_weighted">[docs]</a><span class="k">def</span> <span class="nf">harmonic_mean_weighted</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">ratio</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Harmonic mean of two numbers with a weight ratio. Returns a float</span>

<span class="sd">    ::</span>

<span class="sd">        &gt;&gt;&gt; harmonic_mean_weighted(1, 3, ratio=1.0)</span>
<span class="sd">        1.5</span>
<span class="sd">        &gt;&gt;&gt; harmonic_mean_weighted(1, 3, ratio=0.0)</span>
<span class="sd">        1.0</span>
<span class="sd">        &gt;&gt;&gt; harmonic_mean_weighted(1, 3, ratio=float(&#39;inf&#39;))</span>
<span class="sd">        3.0</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">lweight</span><span class="p">,</span> <span class="n">rweight</span> <span class="o">=</span> <span class="n">ratio2weights</span><span class="p">(</span><span class="n">ratio</span><span class="p">)</span>
    <span class="k">return</span> <span class="nb">float</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">if</span> <span class="n">x</span> <span class="o">==</span> <span class="n">y</span> <span class="k">else</span> <span class="p">(</span><span class="n">x</span> <span class="o">*</span> <span class="n">y</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">lweight</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="n">rweight</span> <span class="o">*</span> <span class="n">y</span><span class="p">)</span></div>


<div class="viewcode-block" id="ContingencyTable"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.ContingencyTable">[docs]</a><span class="k">class</span> <span class="nc">ContingencyTable</span><span class="p">(</span><span class="n">CrossTab</span><span class="p">):</span>

    <span class="c1"># Note: not subclassing Pandas DataFrame because the goal is to specifically</span>
    <span class="c1"># optimize for sparse use cases when &gt;90% of the table consists of zeros.</span>
    <span class="c1"># As of today, Pandas &#39;crosstab&#39; implementation of frequency tables forces</span>
    <span class="c1"># one to iterate on all the zeros, which is horrible...</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="n">CrossTab</span><span class="o">.</span><span class="n">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_assignment_cost</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_expected_freqs_</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_expected_freqs_discrete_</span> <span class="o">=</span> <span class="p">{}</span>

<div class="viewcode-block" id="ContingencyTable.to_array"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.ContingencyTable.to_array">[docs]</a>    <span class="k">def</span> <span class="nf">to_array</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">cpad</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">rpad</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Convert to NumPy array</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">rows</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_rows</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="n">default</span><span class="p">,</span> <span class="n">cpad</span><span class="o">=</span><span class="n">cpad</span><span class="p">,</span> <span class="n">rpad</span><span class="o">=</span><span class="n">rpad</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">rows</span><span class="p">)</span></div>

    <span class="c1"># Factory methods</span>

<div class="viewcode-block" id="ContingencyTable.expected_freqs_"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.ContingencyTable.expected_freqs_">[docs]</a>    <span class="k">def</span> <span class="nf">expected_freqs_</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="s1">&#39;m3&#39;</span><span class="p">):</span>
        <span class="n">table</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_expected_freqs_</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">table</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">table</span>

        <span class="n">N</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">grand_total</span><span class="p">)</span>
        <span class="n">row_margin</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">row_totals</span>
        <span class="n">col_margin</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">col_totals</span>
        <span class="n">R</span><span class="p">,</span> <span class="n">C</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape</span>

        <span class="k">if</span> <span class="n">model</span> <span class="o">==</span> <span class="s1">&#39;m1&#39;</span><span class="p">:</span>                <span class="c1"># no fixed margin</span>
            <span class="n">rows</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_row_type_2d</span><span class="p">()</span>
            <span class="n">expected</span> <span class="o">=</span> <span class="n">N</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">row_margin</span><span class="p">)</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">col_margin</span><span class="p">))</span>
            <span class="k">for</span> <span class="p">(</span><span class="n">ri</span><span class="p">,</span> <span class="n">ci</span><span class="p">),</span> <span class="n">_</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">iter_all</span><span class="p">():</span>
                <span class="n">rows</span><span class="p">[</span><span class="n">ri</span><span class="p">][</span><span class="n">ci</span><span class="p">]</span> <span class="o">=</span> <span class="n">expected</span>
        <span class="k">elif</span> <span class="n">model</span> <span class="o">==</span> <span class="s1">&#39;m2r&#39;</span><span class="p">:</span>             <span class="c1"># fixed row margin</span>
            <span class="n">rows</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_row_type_2d</span><span class="p">()</span>
            <span class="n">cm</span> <span class="o">=</span> <span class="n">N</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">col_margin</span><span class="p">))</span>
            <span class="k">for</span> <span class="p">(</span><span class="n">ri</span><span class="p">,</span> <span class="n">ci</span><span class="p">),</span> <span class="n">_</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">iter_all</span><span class="p">():</span>
                <span class="n">rm</span> <span class="o">=</span> <span class="n">row_margin</span><span class="p">[</span><span class="n">ri</span><span class="p">]</span>
                <span class="n">numer</span> <span class="o">=</span> <span class="n">rm</span> <span class="o">*</span> <span class="n">cm</span>
                <span class="k">if</span> <span class="n">numer</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">rows</span><span class="p">[</span><span class="n">ri</span><span class="p">][</span><span class="n">ci</span><span class="p">]</span> <span class="o">=</span> <span class="n">numer</span> <span class="o">/</span> <span class="n">N</span>
        <span class="k">elif</span> <span class="n">model</span> <span class="o">==</span> <span class="s1">&#39;m2c&#39;</span><span class="p">:</span>             <span class="c1"># fixed column margin</span>
            <span class="n">rows</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_row_type_2d</span><span class="p">()</span>
            <span class="n">rm</span> <span class="o">=</span> <span class="n">N</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">row_margin</span><span class="p">))</span>
            <span class="k">for</span> <span class="p">(</span><span class="n">ri</span><span class="p">,</span> <span class="n">ci</span><span class="p">),</span> <span class="n">_</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">iter_all</span><span class="p">():</span>
                <span class="n">cm</span> <span class="o">=</span> <span class="n">col_margin</span><span class="p">[</span><span class="n">ci</span><span class="p">]</span>
                <span class="n">numer</span> <span class="o">=</span> <span class="n">rm</span> <span class="o">*</span> <span class="n">cm</span>
                <span class="k">if</span> <span class="n">numer</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">rows</span><span class="p">[</span><span class="n">ri</span><span class="p">][</span><span class="n">ci</span><span class="p">]</span> <span class="o">=</span> <span class="n">numer</span> <span class="o">/</span> <span class="n">N</span>
        <span class="k">elif</span> <span class="n">model</span> <span class="o">==</span> <span class="s1">&#39;m3&#39;</span><span class="p">:</span>              <span class="c1"># fixed row *and* column margin</span>
            <span class="n">rows</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_row_type_2d</span><span class="p">()</span>
            <span class="k">for</span> <span class="p">(</span><span class="n">ri</span><span class="p">,</span> <span class="n">ci</span><span class="p">),</span> <span class="n">_</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">iter_all</span><span class="p">():</span>
                <span class="n">rm</span> <span class="o">=</span> <span class="n">row_margin</span><span class="p">[</span><span class="n">ri</span><span class="p">]</span>
                <span class="n">cm</span> <span class="o">=</span> <span class="n">col_margin</span><span class="p">[</span><span class="n">ci</span><span class="p">]</span>
                <span class="n">numer</span> <span class="o">=</span> <span class="n">rm</span> <span class="o">*</span> <span class="n">cm</span>
                <span class="k">if</span> <span class="n">numer</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">rows</span><span class="p">[</span><span class="n">ri</span><span class="p">][</span><span class="n">ci</span><span class="p">]</span> <span class="o">=</span> <span class="n">numer</span> <span class="o">/</span> <span class="n">N</span>
        <span class="k">elif</span> <span class="n">model</span> <span class="o">==</span> <span class="s1">&#39;x1&#39;</span><span class="p">:</span>                <span class="c1"># no fixed margin</span>
            <span class="n">rows</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">R</span><span class="p">,</span> <span class="n">C</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
            <span class="n">rows</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">grand_total</span>
        <span class="k">elif</span> <span class="n">model</span> <span class="o">==</span> <span class="s1">&#39;x2r&#39;</span><span class="p">:</span>             <span class="c1"># fixed row margin</span>
            <span class="n">rows</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">R</span><span class="p">,</span> <span class="n">C</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">rm</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">iter_row_totals</span><span class="p">()):</span>
                <span class="n">rows</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">rm</span>
        <span class="k">elif</span> <span class="n">model</span> <span class="o">==</span> <span class="s1">&#39;x2c&#39;</span><span class="p">:</span>             <span class="c1"># fixed column margin</span>
            <span class="n">rows</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">R</span><span class="p">,</span> <span class="n">C</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">cm</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">iter_col_totals</span><span class="p">()):</span>
                <span class="n">rows</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">cm</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_expected_freqs_</span><span class="p">[</span><span class="n">model</span><span class="p">]</span> <span class="o">=</span> <span class="n">table</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__class__</span><span class="p">(</span><span class="n">rows</span><span class="o">=</span><span class="n">rows</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">table</span></div>

<div class="viewcode-block" id="ContingencyTable.expected"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.ContingencyTable.expected">[docs]</a>    <span class="k">def</span> <span class="nf">expected</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="s1">&#39;m3&#39;</span><span class="p">,</span> <span class="n">discrete</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">redraw</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Factory creating expected table given current margins</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">discrete</span><span class="p">:</span>
            <span class="n">table</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_expected_freqs_discrete_</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">table</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">expected_freqs_</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>

        <span class="c1"># continuous</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">discrete</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">table</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;line should be unreachable&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">table</span>

        <span class="c1"># discrete</span>
        <span class="k">if</span> <span class="n">table</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">redraw</span><span class="p">:</span>
            <span class="n">continuous</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">expected_freqs_</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
            <span class="n">rows</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_row_type_2d</span><span class="p">()</span>

            <span class="c1"># create a sparse instance</span>
            <span class="k">for</span> <span class="p">(</span><span class="n">ri</span><span class="p">,</span> <span class="n">ci</span><span class="p">),</span> <span class="n">expected</span> <span class="ow">in</span> <span class="n">continuous</span><span class="o">.</span><span class="n">iteritems</span><span class="p">():</span>
                <span class="n">expected</span> <span class="o">=</span> <span class="n">randround</span><span class="p">(</span><span class="n">expected</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">expected</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">rows</span><span class="p">[</span><span class="n">ri</span><span class="p">][</span><span class="n">ci</span><span class="p">]</span> <span class="o">=</span> <span class="n">expected</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">_expected_freqs_discrete_</span><span class="p">[</span><span class="n">model</span><span class="p">]</span> <span class="o">=</span> <span class="n">table</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__class__</span><span class="p">(</span><span class="n">rows</span><span class="o">=</span><span class="n">rows</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">table</span></div>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_normalize_measure</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">maximum</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">center</span><span class="o">=</span><span class="mf">0.0</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Normalize to maximum with optional centering</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">isiterable</span><span class="p">(</span><span class="n">value</span><span class="p">):</span>
            <span class="n">value</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">isiterable</span><span class="p">(</span><span class="n">center</span><span class="p">):</span>
            <span class="n">center</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">center</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">isiterable</span><span class="p">(</span><span class="n">maximum</span><span class="p">):</span>
            <span class="n">maximum</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">maximum</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">divide</span><span class="p">(</span><span class="n">value</span> <span class="o">-</span> <span class="n">center</span><span class="p">,</span> <span class="n">maximum</span> <span class="o">-</span> <span class="n">center</span><span class="p">)</span>

<div class="viewcode-block" id="ContingencyTable.adjust_to_null"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.ContingencyTable.adjust_to_null">[docs]</a>    <span class="k">def</span> <span class="nf">adjust_to_null</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">measure</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="s1">&#39;m3&#39;</span><span class="p">,</span> <span class="n">with_warnings</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Adjust a measure to null model</span>

<span class="sd">        The general formula for chance correction of an association measure</span>
<span class="sd">        :math:`M` is:</span>

<span class="sd">        .. math::</span>

<span class="sd">            M_{adj} = \\frac{M - E(M)}{M_{max} - E(M)},</span>

<span class="sd">        where :math:`M_{max}` is the maximum value a measure :math:`M` can</span>
<span class="sd">        achieve, and :math:`E(M)` is the expected value of :math:`M` under</span>
<span class="sd">        statistical independence given fixed table margins. In simple cases,</span>
<span class="sd">        the expected value of a measure is the same as the value of the measure</span>
<span class="sd">        given a null model. This is not always the case, however, and, to</span>
<span class="sd">        properly adjust for chance, sometimes one has average over all possible</span>
<span class="sd">        contingency tables using hypergeometric distribution for example.</span>

<span class="sd">        The method returns a tuple for two different measure ceilings: row-</span>
<span class="sd">        diagonal and column-diagonal. For symmetric measures, the two values</span>
<span class="sd">        will be the same.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">callable</span><span class="p">(</span><span class="n">measure</span><span class="p">):</span>
            <span class="n">measure</span> <span class="o">=</span> <span class="n">measure</span><span class="o">.</span><span class="n">__name__</span>
        <span class="n">actual</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">measure</span><span class="p">)()</span>
        <span class="n">model</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">expected</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">),</span> <span class="n">measure</span><span class="p">)()</span>
        <span class="k">if</span> <span class="n">with_warnings</span> <span class="ow">and</span> <span class="n">np</span><span class="o">.</span><span class="n">isclose</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">model</span><span class="p">),</span> <span class="mf">0.0</span><span class="p">):</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;&#39;</span><span class="si">%s</span><span class="s2">&#39; is already centered&quot;</span> <span class="o">%</span> <span class="n">measure</span><span class="p">)</span>
        <span class="n">max_row</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">row_diag</span><span class="p">(),</span> <span class="n">measure</span><span class="p">)()</span>
        <span class="k">if</span> <span class="n">with_warnings</span> <span class="ow">and</span> <span class="n">np</span><span class="o">.</span><span class="n">isclose</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">max_row</span><span class="p">),</span> <span class="mf">1.0</span><span class="p">):</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;&#39;</span><span class="si">%s</span><span class="s2">&#39; is already row-normalized&quot;</span> <span class="o">%</span> <span class="n">measure</span><span class="p">)</span>
        <span class="n">max_col</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">col_diag</span><span class="p">(),</span> <span class="n">measure</span><span class="p">)()</span>
        <span class="k">if</span> <span class="n">with_warnings</span> <span class="ow">and</span> <span class="n">np</span><span class="o">.</span><span class="n">isclose</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">max_col</span><span class="p">),</span> <span class="mf">1.0</span><span class="p">):</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;&#39;</span><span class="si">%s</span><span class="s2">&#39; is already column-normalized&quot;</span> <span class="o">%</span> <span class="n">measure</span><span class="p">)</span>
        <span class="n">row_adjusted</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_normalize_measure</span><span class="p">(</span><span class="n">actual</span><span class="p">,</span> <span class="n">max_row</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
        <span class="n">col_adjusted</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_normalize_measure</span><span class="p">(</span><span class="n">actual</span><span class="p">,</span> <span class="n">max_col</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">row_adjusted</span><span class="p">,</span> <span class="n">col_adjusted</span></div>

<div class="viewcode-block" id="ContingencyTable.row_diag"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.ContingencyTable.row_diag">[docs]</a>    <span class="k">def</span> <span class="nf">row_diag</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Factory creating diagonal table given current row margin</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">rows</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_row_type_2d</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">iter_items</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">row_totals</span><span class="p">):</span>
            <span class="n">rows</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">m</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">__class__</span><span class="p">(</span><span class="n">rows</span><span class="o">=</span><span class="n">rows</span><span class="p">)</span></div>

<div class="viewcode-block" id="ContingencyTable.col_diag"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.ContingencyTable.col_diag">[docs]</a>    <span class="k">def</span> <span class="nf">col_diag</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Factory creating diagonal table given current column margin</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">rows</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_row_type_2d</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">iter_items</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">col_totals</span><span class="p">):</span>
            <span class="n">rows</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">m</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">__class__</span><span class="p">(</span><span class="n">rows</span><span class="o">=</span><span class="n">rows</span><span class="p">)</span></div>

    <span class="c1"># Misc metrics</span>
<div class="viewcode-block" id="ContingencyTable.chisq_score"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.ContingencyTable.chisq_score">[docs]</a>    <span class="k">def</span> <span class="nf">chisq_score</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Pearson&#39;s chi-square statistic</span>

<span class="sd">        &gt;&gt;&gt; r = {1: {1: 16, 3: 2}, 2: {1: 1, 2: 3}, 3: {1: 4, 2: 5, 3: 5}}</span>
<span class="sd">        &gt;&gt;&gt; cm = ContingencyTable(rows=r)</span>
<span class="sd">        &gt;&gt;&gt; round(cm.chisq_score(), 3)</span>
<span class="sd">        19.256</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">N</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">grand_total</span><span class="p">)</span>
        <span class="n">score</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="k">for</span> <span class="n">rm</span><span class="p">,</span> <span class="n">cm</span><span class="p">,</span> <span class="n">observed</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">iter_all_with_margins</span><span class="p">():</span>
            <span class="n">numer</span> <span class="o">=</span> <span class="n">rm</span> <span class="o">*</span> <span class="n">cm</span>
            <span class="k">if</span> <span class="n">numer</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">expected</span> <span class="o">=</span> <span class="n">numer</span> <span class="o">/</span> <span class="n">N</span>
                <span class="n">score</span> <span class="o">+=</span> <span class="p">(</span><span class="n">observed</span> <span class="o">-</span> <span class="n">expected</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">/</span> <span class="n">expected</span>
        <span class="k">return</span> <span class="n">score</span></div>

<div class="viewcode-block" id="ContingencyTable.g_score"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.ContingencyTable.g_score">[docs]</a>    <span class="k">def</span> <span class="nf">g_score</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;G-statistic for RxC contingency table</span>

<span class="sd">        This method does not perform any corrections to this statistic (e.g.</span>
<span class="sd">        Williams&#39;, Yates&#39; corrections).</span>

<span class="sd">        The statistic is equivalent to the negative of Mutual Information times</span>
<span class="sd">        two.  Mututal Information on a contingency table is defined as the</span>
<span class="sd">        difference between the information in the table and the information in</span>
<span class="sd">        an independent table with the same margins.  For application of mutual</span>
<span class="sd">        information (in the form of G-score) to search for collocated words in</span>
<span class="sd">        NLP, see [1]_ and [2]_.</span>

<span class="sd">        References</span>
<span class="sd">        ----------</span>

<span class="sd">        .. [1] `Dunning, T. (1993). Accurate methods for the statistics of</span>
<span class="sd">               surprise and coincidence. Computational linguistics, 19(1), 61-74.</span>
<span class="sd">               &lt;http://dl.acm.org/citation.cfm?id=972454&gt;`_</span>

<span class="sd">        .. [2] `Ted Dunning&#39;s personal blog entry and the discussion under it.</span>
<span class="sd">               &lt;http://tdunning.blogspot.com/2008/03/surprise-and-coincidence.html&gt;`_</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">I_CK</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_entropies</span><span class="p">()</span>
        <span class="k">return</span> <span class="mf">2.0</span> <span class="o">*</span> <span class="n">I_CK</span></div>

    <span class="k">def</span> <span class="nf">_entropies</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return H_C, H_K, and mutual information</span>

<span class="sd">        Not normalized by N</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">H_C</span> <span class="o">=</span> <span class="n">fentropy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">row_totals</span><span class="p">)</span>
        <span class="n">H_K</span> <span class="o">=</span> <span class="n">fentropy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">col_totals</span><span class="p">)</span>
        <span class="n">H_actual</span> <span class="o">=</span> <span class="n">fentropy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">itervalues</span><span class="p">())</span>
        <span class="n">H_expected</span> <span class="o">=</span> <span class="n">H_C</span> <span class="o">+</span> <span class="n">H_K</span>
        <span class="n">I_CK</span> <span class="o">=</span> <span class="n">H_expected</span> <span class="o">-</span> <span class="n">H_actual</span>
        <span class="k">return</span> <span class="n">H_C</span><span class="p">,</span> <span class="n">H_K</span><span class="p">,</span> <span class="n">I_CK</span>

<div class="viewcode-block" id="ContingencyTable.mutual_info_score"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.ContingencyTable.mutual_info_score">[docs]</a>    <span class="k">def</span> <span class="nf">mutual_info_score</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Mutual Information Score</span>

<span class="sd">        Mutual Information (divided by N).</span>

<span class="sd">        The metric is equal to the Kullback-Leibler divergence of the joint</span>
<span class="sd">        distribution with the product distribution of the marginals.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">I_CK</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_entropies</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">I_CK</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">grand_total</span></div>

<div class="viewcode-block" id="ContingencyTable.entropy_scores"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.ContingencyTable.entropy_scores">[docs]</a>    <span class="k">def</span> <span class="nf">entropy_scores</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="s1">&#39;harmonic&#39;</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Gives three entropy-based metrics for a RxC table</span>

<span class="sd">        The metrics are: Homogeneity, Completeness, and V-measure</span>

<span class="sd">        The V-measure metric is also known as Normalized Mutual Information</span>
<span class="sd">        (NMI), and is calculated here as the harmonic mean of Homogeneity and</span>
<span class="sd">        Completeness (:math:`NMI_{sum}`). There exist other definitions of NMI (see</span>
<span class="sd">        Table 2 in [1]_ for a good review).</span>

<span class="sd">        Homogeneity and Completeness are duals of each other and can be thought</span>
<span class="sd">        of (although this is not technically accurate) as squared regression</span>
<span class="sd">        coefficients of a given clustering vs true labels (homogeneity) and of</span>
<span class="sd">        the dual problem of true labels vs given clustering (completeness).</span>
<span class="sd">        Because of the dual property, in a symmetric matrix, all three scores</span>
<span class="sd">        are the same. Homogeneity has an overall profile similar to that of</span>
<span class="sd">        precision in information retrieval. Completeness roughly corresponds to</span>
<span class="sd">        recall.</span>

<span class="sd">        This method replaces ``homogeneity_completeness_v_measure`` method in</span>
<span class="sd">        Scikit-Learn.  The Scikit-Learn version takes up :math:`O(n^2)` space</span>
<span class="sd">        because it stores data in a dense NumPy array, while the given version</span>
<span class="sd">        is sub-quadratic because of sparse underlying storage.</span>

<span class="sd">        Note that the entropy variables H in the code below are improperly</span>
<span class="sd">        defined because they ought to be divided by N (the grand total for the</span>
<span class="sd">        contingency table). However, the N variable cancels out during</span>
<span class="sd">        normalization.</span>

<span class="sd">        References</span>
<span class="sd">        ----------</span>

<span class="sd">        .. [1] `Vinh, N. X., Epps, J., &amp; Bailey, J. (2010). Information theoretic</span>
<span class="sd">               measures for clusterings comparison: Variants, properties,</span>
<span class="sd">               normalization and correction for chance. The Journal of Machine</span>
<span class="sd">               Learning Research, 11, 2837-2854.</span>
<span class="sd">               &lt;http://www.jmlr.org/papers/v11/vinh10a.html&gt;`_</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># ensure non-negative values by taking max of 0 and given value</span>
        <span class="n">H_C</span><span class="p">,</span> <span class="n">H_K</span><span class="p">,</span> <span class="n">I_CK</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_entropies</span><span class="p">()</span>
        <span class="n">h</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="k">if</span> <span class="n">H_C</span> <span class="o">==</span> <span class="mf">0.0</span> <span class="k">else</span> <span class="nb">max</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">I_CK</span> <span class="o">/</span> <span class="n">H_C</span><span class="p">)</span>
        <span class="n">c</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="k">if</span> <span class="n">H_K</span> <span class="o">==</span> <span class="mf">0.0</span> <span class="k">else</span> <span class="nb">max</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">I_CK</span> <span class="o">/</span> <span class="n">H_K</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">mean</span> <span class="o">==</span> <span class="s1">&#39;harmonic&#39;</span><span class="p">:</span>
            <span class="n">rsquare</span> <span class="o">=</span> <span class="n">harmonic_mean</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">mean</span> <span class="o">==</span> <span class="s1">&#39;geometric&#39;</span><span class="p">:</span>
            <span class="n">rsquare</span> <span class="o">=</span> <span class="n">geometric_mean</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="n">mean</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">h</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">rsquare</span></div>

<div class="viewcode-block" id="ContingencyTable.adjusted_mutual_info"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.ContingencyTable.adjusted_mutual_info">[docs]</a>    <span class="k">def</span> <span class="nf">adjusted_mutual_info</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Adjusted Mutual Information for two partitions</span>

<span class="sd">        For a mathematical definition, see [1]_, [2]_, and [2]_.</span>

<span class="sd">        References</span>
<span class="sd">        ----------</span>

<span class="sd">        .. [1] `Vinh, N. X., Epps, J., &amp; Bailey, J. (2009, June). Information</span>
<span class="sd">               theoretic measures for clusterings comparison: is a correction</span>
<span class="sd">               for chance necessary?. In Proceedings of the 26th Annual</span>
<span class="sd">               International Conference on Machine Learning (pp. 1073-1080).</span>
<span class="sd">               ACM.</span>
<span class="sd">               &lt;https://doi.org/10.1145/1553374.1553511&gt;`_</span>

<span class="sd">        .. [2] `Vinh, N. X., &amp; Epps, J. (2009, June). A novel approach for</span>
<span class="sd">               automatic number of clusters detection in microarray data based</span>
<span class="sd">               on consensus clustering. In Bioinformatics and BioEngineering,</span>
<span class="sd">               2009.  BIBE&#39;09. Ninth IEEE International Conference on (pp.</span>
<span class="sd">               84-91). IEEE.</span>
<span class="sd">               &lt;http://dx.doi.org/10.1109/BIBE.2009.19&gt;`_</span>

<span class="sd">        .. [3] `Vinh, N. X., Epps, J., &amp; Bailey, J. (2010). Information theoretic</span>
<span class="sd">               measures for clusterings comparison: Variants, properties,</span>
<span class="sd">               normalization and correction for chance. The Journal of Machine</span>
<span class="sd">               Learning Research, 11, 2837-2854.</span>
<span class="sd">               &lt;http://www.jmlr.org/papers/v11/vinh10a.html&gt;`_</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Prepare row totals and check for special cases</span>
        <span class="n">row_totals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">fromiter</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">iter_row_totals</span><span class="p">(),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
        <span class="n">col_totals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">fromiter</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">iter_col_totals</span><span class="p">(),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
        <span class="n">R</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">row_totals</span><span class="p">)</span>
        <span class="n">C</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">col_totals</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">R</span> <span class="o">==</span> <span class="n">C</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">or</span> <span class="n">R</span> <span class="o">==</span> <span class="n">C</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># No clustering since the data is not split. This is a perfect match</span>
            <span class="c1"># hence return 1.0.</span>
            <span class="k">return</span> <span class="mf">1.0</span>

        <span class="c1"># In one step, calculate entropy for each labeling and mutual</span>
        <span class="c1"># information</span>
        <span class="n">h_true</span><span class="p">,</span> <span class="n">h_pred</span><span class="p">,</span> <span class="n">mi</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_entropies</span><span class="p">()</span>
        <span class="n">mi_max</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">h_true</span><span class="p">,</span> <span class="n">h_pred</span><span class="p">)</span>

        <span class="c1"># Calculate the expected value for the MI</span>
        <span class="n">emi</span> <span class="o">=</span> <span class="n">emi_from_margins</span><span class="p">(</span><span class="n">row_totals</span><span class="p">,</span> <span class="n">col_totals</span><span class="p">)</span>

        <span class="c1"># Calculate the adjusted MI score</span>
        <span class="n">ami</span> <span class="o">=</span> <span class="p">(</span><span class="n">mi</span> <span class="o">-</span> <span class="n">emi</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">mi_max</span> <span class="o">-</span> <span class="n">emi</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">ami</span></div>

<div class="viewcode-block" id="ContingencyTable.assignment_score_m1"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.ContingencyTable.assignment_score_m1">[docs]</a>    <span class="k">def</span> <span class="nf">assignment_score_m1</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">redraw</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">assignment_score</span><span class="p">(</span>
            <span class="n">normalize</span><span class="o">=</span><span class="n">normalize</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="s1">&#39;m1&#39;</span><span class="p">,</span> <span class="n">discrete</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">redraw</span><span class="o">=</span><span class="n">redraw</span><span class="p">)</span></div>

<div class="viewcode-block" id="ContingencyTable.assignment_score_m2r"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.ContingencyTable.assignment_score_m2r">[docs]</a>    <span class="k">def</span> <span class="nf">assignment_score_m2r</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">redraw</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">assignment_score</span><span class="p">(</span>
            <span class="n">normalize</span><span class="o">=</span><span class="n">normalize</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="s1">&#39;m2r&#39;</span><span class="p">,</span> <span class="n">discrete</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">redraw</span><span class="o">=</span><span class="n">redraw</span><span class="p">)</span></div>

<div class="viewcode-block" id="ContingencyTable.assignment_score_m2c"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.ContingencyTable.assignment_score_m2c">[docs]</a>    <span class="k">def</span> <span class="nf">assignment_score_m2c</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">redraw</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">assignment_score</span><span class="p">(</span>
            <span class="n">normalize</span><span class="o">=</span><span class="n">normalize</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="s1">&#39;m2c&#39;</span><span class="p">,</span> <span class="n">discrete</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">redraw</span><span class="o">=</span><span class="n">redraw</span><span class="p">)</span></div>

<div class="viewcode-block" id="ContingencyTable.assignment_score_m3"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.ContingencyTable.assignment_score_m3">[docs]</a>    <span class="k">def</span> <span class="nf">assignment_score_m3</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">redraw</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">assignment_score</span><span class="p">(</span>
            <span class="n">normalize</span><span class="o">=</span><span class="n">normalize</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="s1">&#39;m3&#39;</span><span class="p">,</span> <span class="n">discrete</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">redraw</span><span class="o">=</span><span class="n">redraw</span><span class="p">)</span></div>

<div class="viewcode-block" id="ContingencyTable.assignment_score"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.ContingencyTable.assignment_score">[docs]</a>    <span class="k">def</span> <span class="nf">assignment_score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="s1">&#39;m1&#39;</span><span class="p">,</span>
                         <span class="n">discrete</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">redraw</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Similarity score by solving the Linear Sum Assignment Problem</span>

<span class="sd">        This metric is uniformly more powerful than the similarly behaved</span>
<span class="sd">        ``split_join_similarity`` which relies on an approximation to the</span>
<span class="sd">        optimal solution evaluated here. The split-join approximation</span>
<span class="sd">        asymptotically approaches the optimal solution as the clustering</span>
<span class="sd">        quality improves.</span>

<span class="sd">        On the ``model`` parameter: adjusting assignment cost for chance</span>
<span class="sd">        by relying on the hypergeometric distribution is extremely</span>
<span class="sd">        computationally expensive, but one way to get a better behaved metric</span>
<span class="sd">        is to just subtract the cost of a null model from the obtained score</span>
<span class="sd">        (in case of normalization, the null cost also has to be subtracted from</span>
<span class="sd">        the maximum cost). Note that on large tables even finding the null cost</span>
<span class="sd">        is too expensive, since expected tables have a lot less sparsity. Hence</span>
<span class="sd">        the parameter is off by default.</span>

<span class="sd">        Alternatively this problem can be recast as that of finding a *maximum</span>
<span class="sd">        weighted bipartite match* [1]_.</span>

<span class="sd">        This method of partition comparison was first mentioned in [2]_, given</span>
<span class="sd">        an approximation in [3]_, formally elaborated in [4]_ and empirically</span>
<span class="sd">        compared with other measures in [5]_.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        split_join_similarity</span>

<span class="sd">        References</span>
<span class="sd">        ----------</span>

<span class="sd">        .. [1] `Wikipedia entry on weighted bipartite graph matching</span>
<span class="sd">               &lt;https://en.wikipedia.org/wiki/Matching_%28graph_theory%28#In_weighted_bipartite_graphs&gt;`_</span>

<span class="sd">        .. [2] `Almudevar, A., &amp; Field, C. (1999). Estimation of</span>
<span class="sd">               single-generation sibling relationships based on DNA markers.</span>
<span class="sd">               Journal of agricultural, biological, and environmental</span>
<span class="sd">               statistics, 136-165.</span>
<span class="sd">               &lt;http://www.jstor.org/stable/1400594&gt;`_</span>

<span class="sd">        .. [3] `Ben-Hur, A., &amp; Guyon, I. (2003). Detecting stable clusters</span>
<span class="sd">               using principal component analysis. In Functional Genomics (pp.</span>
<span class="sd">               159-182). Humana press.</span>
<span class="sd">               &lt;http://doi.org/10.1385/1-59259-364-X:159&gt;`_</span>

<span class="sd">        .. [4] `Gusfield, D. (2002). Partition-distance: A problem and class of</span>
<span class="sd">               perfect graphs arising in clustering. Information Processing</span>
<span class="sd">               Letters, 82(3), 159-164.</span>
<span class="sd">               &lt;http://doi.org/10.1016/S0020-0190%2801%2900263-0&gt;`_</span>

<span class="sd">        .. [5] `Giurcaneanu, C. D., &amp; Tabus, I. (2004). Cluster structure</span>
<span class="sd">               inference based on clustering stability with applications to</span>
<span class="sd">               microarray data analysis. EURASIP Journal on Applied Signal</span>
<span class="sd">               Processing, 2004, 64-80.</span>
<span class="sd">               &lt;http://dl.acm.org/citation.cfm?id=1289345&gt;`_</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># computing assignment cost is expensive so we cache it</span>
        <span class="n">cost</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_assignment_cost</span>

        <span class="k">if</span> <span class="n">cost</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># guess matrix dtype</span>
            <span class="n">cost</span> <span class="o">=</span> <span class="n">assignment_cost</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">to_rows</span><span class="p">(),</span> <span class="n">maximize</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_assignment_cost</span> <span class="o">=</span> <span class="n">cost</span>

        <span class="n">N</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">grand_total</span>
        <span class="n">R</span><span class="p">,</span> <span class="n">C</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape</span>

        <span class="k">if</span> <span class="n">model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">null_cost</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">elif</span> <span class="p">(</span><span class="ow">not</span> <span class="n">discrete</span><span class="p">)</span> <span class="ow">and</span> <span class="n">model</span> <span class="o">==</span> <span class="s1">&#39;m1&#39;</span><span class="p">:</span>
            <span class="c1"># No margin is fixed, assignment doesn&#39;t matter (all cells are</span>
            <span class="c1"># equal under this assumption), so we can calculate expected cost</span>
            <span class="c1"># directly</span>
            <span class="n">null_cost</span> <span class="o">=</span> <span class="n">N</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="n">C</span><span class="p">))</span>
        <span class="k">elif</span> <span class="p">(</span><span class="ow">not</span> <span class="n">discrete</span><span class="p">)</span> <span class="ow">and</span> <span class="n">model</span> <span class="o">==</span> <span class="s1">&#39;m2r&#39;</span><span class="p">:</span>
            <span class="c1"># fixed row margin, assignment also doesn&#39;t matter</span>
            <span class="n">sum_top_rows</span> <span class="o">=</span> <span class="n">N</span> <span class="k">if</span> <span class="n">R</span> <span class="o">&lt;=</span> <span class="n">C</span> <span class="k">else</span> \
                <span class="nb">sum</span><span class="p">(</span><span class="nb">sorted</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">row_totals</span><span class="o">.</span><span class="n">itervalues</span><span class="p">(),</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)[:</span><span class="n">C</span><span class="p">])</span>
            <span class="n">null_cost</span> <span class="o">=</span> <span class="n">sum_top_rows</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">C</span><span class="p">)</span>
        <span class="k">elif</span> <span class="p">(</span><span class="ow">not</span> <span class="n">discrete</span><span class="p">)</span> <span class="ow">and</span> <span class="n">model</span> <span class="o">==</span> <span class="s1">&#39;m2c&#39;</span><span class="p">:</span>
            <span class="c1"># fixed column margin, assignment also doesn&#39;t matter</span>
            <span class="n">sum_top_cols</span> <span class="o">=</span> <span class="n">N</span> <span class="k">if</span> <span class="n">C</span> <span class="o">&lt;=</span> <span class="n">R</span> <span class="k">else</span> \
                <span class="nb">sum</span><span class="p">(</span><span class="nb">sorted</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">col_totals</span><span class="o">.</span><span class="n">itervalues</span><span class="p">(),</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)[:</span><span class="n">R</span><span class="p">])</span>
            <span class="n">null_cost</span> <span class="o">=</span> <span class="n">sum_top_cols</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">R</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># all margins fixed, assignment matters</span>
            <span class="n">expected</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">expected</span><span class="p">(</span>
                <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">discrete</span><span class="o">=</span><span class="n">discrete</span><span class="p">,</span> <span class="n">redraw</span><span class="o">=</span><span class="n">redraw</span><span class="p">)</span>
            <span class="n">null_cost</span> <span class="o">=</span> <span class="n">expected</span><span class="o">.</span><span class="n">assignment_score</span><span class="p">(</span>
                <span class="n">model</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="n">cost</span> <span class="o">-=</span> <span class="n">null_cost</span>
        <span class="k">if</span> <span class="n">normalize</span><span class="p">:</span>
            <span class="n">max_cost</span> <span class="o">=</span> <span class="n">N</span> <span class="o">-</span> <span class="n">null_cost</span>
            <span class="n">cost</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="k">if</span> <span class="n">cost</span> <span class="o">==</span> <span class="n">max_cost</span> <span class="k">else</span> <span class="n">_div</span><span class="p">(</span><span class="n">cost</span><span class="p">,</span> <span class="n">max_cost</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">cost</span></div>

<div class="viewcode-block" id="ContingencyTable.vi_distance"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.ContingencyTable.vi_distance">[docs]</a>    <span class="k">def</span> <span class="nf">vi_distance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Variation of Information distance</span>

<span class="sd">        Defined in [1]_. This is one of several possible entropy-based distance</span>
<span class="sd">        measures that could be defined on a RxC matrix. The given measure is</span>
<span class="sd">        equivalent to :math:`2 D_{sum}` as listed in Table 2 in [2]_.</span>

<span class="sd">        Note that the entropy variables H below are calculated using natural</span>
<span class="sd">        logs, so a base correction may be necessary if you need your result in</span>
<span class="sd">        base 2 for example.</span>

<span class="sd">        References</span>
<span class="sd">        ----------</span>

<span class="sd">        .. [1] `Meila, M. (2007). Comparing clusterings -- an information based</span>
<span class="sd">               distance. Journal of multivariate analysis, 98(5), 873-895.</span>
<span class="sd">               &lt;https://doi.org/10.1016/j.jmva.2006.11.013&gt;`_</span>

<span class="sd">        .. [2] `Vinh, N. X., Epps, J., &amp; Bailey, J. (2010). Information theoretic</span>
<span class="sd">               measures for clusterings comparison: Variants, properties,</span>
<span class="sd">               normalization and correction for chance. The Journal of Machine</span>
<span class="sd">               Learning Research, 11, 2837-2854.</span>
<span class="sd">               &lt;http://www.jmlr.org/papers/v11/vinh10a.html&gt;`_</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">H_C</span><span class="p">,</span> <span class="n">H_K</span><span class="p">,</span> <span class="n">I_CK</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_entropies</span><span class="p">()</span>
        <span class="n">N</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">grand_total</span>
        <span class="n">score</span> <span class="o">=</span> <span class="p">(</span><span class="n">H_C</span> <span class="o">+</span> <span class="n">H_K</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">I_CK</span><span class="p">)</span> <span class="o">/</span> <span class="n">N</span>
        <span class="k">if</span> <span class="n">normalize</span><span class="p">:</span>
            <span class="n">score</span> <span class="o">=</span> <span class="n">_div</span><span class="p">(</span><span class="n">score</span><span class="p">,</span> <span class="n">log</span><span class="p">(</span><span class="n">N</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">score</span></div>

<div class="viewcode-block" id="ContingencyTable.vi_similarity_m1"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.ContingencyTable.vi_similarity_m1">[docs]</a>    <span class="k">def</span> <span class="nf">vi_similarity_m1</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">vi_similarity</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="n">normalize</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="s1">&#39;m1&#39;</span><span class="p">)</span></div>

<div class="viewcode-block" id="ContingencyTable.vi_similarity_m2r"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.ContingencyTable.vi_similarity_m2r">[docs]</a>    <span class="k">def</span> <span class="nf">vi_similarity_m2r</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">vi_similarity</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="n">normalize</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="s1">&#39;m2r&#39;</span><span class="p">)</span></div>

<div class="viewcode-block" id="ContingencyTable.vi_similarity_m2c"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.ContingencyTable.vi_similarity_m2c">[docs]</a>    <span class="k">def</span> <span class="nf">vi_similarity_m2c</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">vi_similarity</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="n">normalize</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="s1">&#39;m2c&#39;</span><span class="p">)</span></div>

<div class="viewcode-block" id="ContingencyTable.vi_similarity_m3"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.ContingencyTable.vi_similarity_m3">[docs]</a>    <span class="k">def</span> <span class="nf">vi_similarity_m3</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">vi_similarity</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="n">normalize</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="s1">&#39;m3&#39;</span><span class="p">)</span></div>

<div class="viewcode-block" id="ContingencyTable.vi_similarity"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.ContingencyTable.vi_similarity">[docs]</a>    <span class="k">def</span> <span class="nf">vi_similarity</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="s1">&#39;m1&#39;</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Inverse of ``vi_distance``</span>

<span class="sd">        The m1 adjustment is monotonic for tables of fixed size. The m3</span>
<span class="sd">        adjustment turns this measure into Normalized Mutual Information (NMI)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">R</span><span class="p">,</span> <span class="n">C</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">N</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">grand_total</span>

        <span class="n">max_dist</span> <span class="o">=</span> <span class="n">log</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>
        <span class="n">dist</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vi_distance</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">score</span> <span class="o">=</span> <span class="n">max_dist</span> <span class="o">-</span> <span class="n">dist</span>

        <span class="k">if</span> <span class="n">model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">null_score</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">elif</span> <span class="n">model</span> <span class="o">==</span> <span class="s1">&#39;m1&#39;</span><span class="p">:</span>         <span class="c1"># only N is fixed</span>
            <span class="n">null_dist</span> <span class="o">=</span> <span class="n">log</span><span class="p">(</span><span class="n">R</span><span class="p">)</span> <span class="o">+</span> <span class="n">log</span><span class="p">(</span><span class="n">C</span><span class="p">)</span>
            <span class="n">null_score</span> <span class="o">=</span> <span class="n">max_dist</span> <span class="o">-</span> <span class="n">null_dist</span>
        <span class="k">elif</span> <span class="n">model</span> <span class="o">==</span> <span class="s1">&#39;m2r&#39;</span><span class="p">:</span>        <span class="c1"># fixed row margin</span>
            <span class="n">null_dist</span> <span class="o">=</span> <span class="n">log</span><span class="p">(</span><span class="n">C</span><span class="p">)</span> <span class="o">+</span> <span class="n">fentropy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">row_totals</span><span class="p">)</span> <span class="o">/</span> <span class="n">N</span>
            <span class="n">null_score</span> <span class="o">=</span> <span class="n">max_dist</span> <span class="o">-</span> <span class="n">null_dist</span>
        <span class="k">elif</span> <span class="n">model</span> <span class="o">==</span> <span class="s1">&#39;m2c&#39;</span><span class="p">:</span>        <span class="c1"># fixed column margin</span>
            <span class="n">null_dist</span> <span class="o">=</span> <span class="n">log</span><span class="p">(</span><span class="n">R</span><span class="p">)</span> <span class="o">+</span> <span class="n">fentropy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">col_totals</span><span class="p">)</span> <span class="o">/</span> <span class="n">N</span>
            <span class="n">null_score</span> <span class="o">=</span> <span class="n">max_dist</span> <span class="o">-</span> <span class="n">null_dist</span>
        <span class="k">elif</span> <span class="n">model</span> <span class="o">==</span> <span class="s1">&#39;m3&#39;</span><span class="p">:</span>         <span class="c1"># both row and column margins fixed</span>
            <span class="n">null_dist</span> <span class="o">=</span> <span class="p">(</span><span class="n">fentropy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">row_totals</span><span class="p">)</span> <span class="o">+</span> <span class="n">fentropy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">col_totals</span><span class="p">))</span> <span class="o">/</span> <span class="n">N</span>
            <span class="n">null_score</span> <span class="o">=</span> <span class="n">max_dist</span> <span class="o">-</span> <span class="n">null_dist</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">expected</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">expected</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
            <span class="n">null_score</span> <span class="o">=</span> <span class="n">expected</span><span class="o">.</span><span class="n">vi_similarity</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

        <span class="n">score</span> <span class="o">-=</span> <span class="n">null_score</span>
        <span class="k">if</span> <span class="n">normalize</span><span class="p">:</span>
            <span class="n">max_score</span> <span class="o">=</span> <span class="n">max_dist</span> <span class="o">-</span> <span class="n">null_score</span>
            <span class="n">score</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="k">if</span> <span class="n">score</span> <span class="o">==</span> <span class="n">max_score</span> <span class="k">else</span> <span class="n">_div</span><span class="p">(</span><span class="n">score</span><span class="p">,</span> <span class="n">max_score</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">score</span></div>

<div class="viewcode-block" id="ContingencyTable.split_join_distance"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.ContingencyTable.split_join_distance">[docs]</a>    <span class="k">def</span> <span class="nf">split_join_distance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Distance metric based on ``split_join_similarity``</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">sim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">split_join_similarity</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
        <span class="n">max_sim</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">grand_total</span>
        <span class="n">score</span> <span class="o">=</span> <span class="n">max_sim</span> <span class="o">-</span> <span class="n">sim</span>
        <span class="k">if</span> <span class="n">normalize</span><span class="p">:</span>
            <span class="n">score</span> <span class="o">=</span> <span class="n">_div</span><span class="p">(</span><span class="n">score</span><span class="p">,</span> <span class="n">max_sim</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">score</span></div>

<div class="viewcode-block" id="ContingencyTable.split_join_similarity_m1"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.ContingencyTable.split_join_similarity_m1">[docs]</a>    <span class="k">def</span> <span class="nf">split_join_similarity_m1</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">split_join_similarity</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="n">normalize</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="s1">&#39;m1&#39;</span><span class="p">)</span></div>

<div class="viewcode-block" id="ContingencyTable.split_join_similarity_m2r"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.ContingencyTable.split_join_similarity_m2r">[docs]</a>    <span class="k">def</span> <span class="nf">split_join_similarity_m2r</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">split_join_similarity</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="n">normalize</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="s1">&#39;m2r&#39;</span><span class="p">)</span></div>

<div class="viewcode-block" id="ContingencyTable.split_join_similarity_m2c"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.ContingencyTable.split_join_similarity_m2c">[docs]</a>    <span class="k">def</span> <span class="nf">split_join_similarity_m2c</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">split_join_similarity</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="n">normalize</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="s1">&#39;m2c&#39;</span><span class="p">)</span></div>

<div class="viewcode-block" id="ContingencyTable.split_join_similarity_m3"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.ContingencyTable.split_join_similarity_m3">[docs]</a>    <span class="k">def</span> <span class="nf">split_join_similarity_m3</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">split_join_similarity</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="n">normalize</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="s1">&#39;m3&#39;</span><span class="p">)</span></div>

<div class="viewcode-block" id="ContingencyTable.split_join_similarity"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.ContingencyTable.split_join_similarity">[docs]</a>    <span class="k">def</span> <span class="nf">split_join_similarity</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="s1">&#39;m1&#39;</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Split-join similarity score</span>

<span class="sd">        Split-join similarity is a two-way assignment-based score first</span>
<span class="sd">        proposed in [1]_. The distance variant of this measure has metric</span>
<span class="sd">        properties.  Like the better known purity score (a one-way</span>
<span class="sd">        coefficient), this measure implicitly performs class-cluster</span>
<span class="sd">        assignment, except the assignment is performed twice: based on the</span>
<span class="sd">        corresponding maximum frequency in the contingency table, each class is</span>
<span class="sd">        given a cluster with the assignment weighted according to the</span>
<span class="sd">        frequency, then the procedure is inversed to assign a class to each</span>
<span class="sd">        cluster. The final unnormalized distance score comprises of a simple</span>
<span class="sd">        sum of the two one-way assignment scores.</span>

<span class="sd">        By default, ``m1`` null model is subtracted, to make the final</span>
<span class="sd">        score independent of the number of clusters::</span>

<span class="sd">            &gt;&gt;&gt; t2 = ClusteringMetrics(rows=10 * np.ones((2, 2), dtype=int))</span>
<span class="sd">            &gt;&gt;&gt; t2.split_join_similarity(model=None)</span>
<span class="sd">            0.5</span>
<span class="sd">            &gt;&gt;&gt; t2.split_join_similarity(model=&#39;m1&#39;)</span>
<span class="sd">            0.0</span>
<span class="sd">            &gt;&gt;&gt; t8 = ClusteringMetrics(rows=10 * np.ones((8, 8), dtype=int))</span>
<span class="sd">            &gt;&gt;&gt; t8.split_join_similarity(model=None)</span>
<span class="sd">            0.125</span>
<span class="sd">            &gt;&gt;&gt; t8.split_join_similarity(model=&#39;m1&#39;)</span>
<span class="sd">            0.0</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        assignment_score</span>

<span class="sd">        References</span>
<span class="sd">        ----------</span>

<span class="sd">        .. [1] `Dongen, S. V. (2000). Performance criteria for graph clustering</span>
<span class="sd">               and Markov cluster experiments. Information Systems [INS],</span>
<span class="sd">               (R 0012), 1-36.</span>
<span class="sd">               &lt;http://dl.acm.org/citation.cfm?id=868979&gt;`_</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">pa_B</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="n">row</span><span class="p">)</span> <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">iter_rows</span><span class="p">())</span>
        <span class="n">pb_A</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="n">col</span><span class="p">)</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">iter_cols</span><span class="p">())</span>
        <span class="n">score</span> <span class="o">=</span> <span class="n">pa_B</span> <span class="o">+</span> <span class="n">pb_A</span>

        <span class="n">N</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">grand_total</span>
        <span class="n">R</span><span class="p">,</span> <span class="n">C</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape</span>

        <span class="k">if</span> <span class="n">model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">null_score</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">elif</span> <span class="n">model</span> <span class="o">==</span> <span class="s1">&#39;m1&#39;</span><span class="p">:</span>         <span class="c1"># only N is fixed</span>
            <span class="n">null_score</span> <span class="o">=</span> <span class="n">N</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">R</span><span class="p">)</span> <span class="o">+</span> <span class="n">N</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">C</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">model</span> <span class="o">==</span> <span class="s1">&#39;m2r&#39;</span><span class="p">:</span>        <span class="c1"># fixed row margin</span>
            <span class="n">null_score</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">row_totals</span><span class="o">.</span><span class="n">itervalues</span><span class="p">())</span> <span class="o">+</span> <span class="n">N</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">C</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">model</span> <span class="o">==</span> <span class="s1">&#39;m2c&#39;</span><span class="p">:</span>        <span class="c1"># fixed column margin</span>
            <span class="n">null_score</span> <span class="o">=</span> <span class="n">N</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">R</span><span class="p">)</span> <span class="o">+</span> <span class="nb">max</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">col_totals</span><span class="o">.</span><span class="n">itervalues</span><span class="p">())</span>
        <span class="k">elif</span> <span class="n">model</span> <span class="o">==</span> <span class="s1">&#39;m3&#39;</span><span class="p">:</span>         <span class="c1"># both row and column margins fixed</span>
            <span class="n">null_score</span> <span class="o">=</span> \
                <span class="nb">max</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">row_totals</span><span class="o">.</span><span class="n">itervalues</span><span class="p">())</span> <span class="o">+</span> \
                <span class="nb">max</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">col_totals</span><span class="o">.</span><span class="n">itervalues</span><span class="p">())</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">expected</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">expected</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
            <span class="n">null_score</span> <span class="o">=</span> <span class="n">expected</span><span class="o">.</span><span class="n">split_join_similarity</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

        <span class="n">score</span> <span class="o">-=</span> <span class="n">null_score</span>
        <span class="k">if</span> <span class="n">normalize</span><span class="p">:</span>
            <span class="n">max_score</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">N</span> <span class="o">-</span> <span class="n">null_score</span>
            <span class="n">score</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="k">if</span> <span class="n">score</span> <span class="o">==</span> <span class="n">max_score</span> <span class="k">else</span> <span class="n">_div</span><span class="p">(</span><span class="n">score</span><span class="p">,</span> <span class="n">max_score</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">score</span></div>

<div class="viewcode-block" id="ContingencyTable.talburt_wang_index"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.ContingencyTable.talburt_wang_index">[docs]</a>    <span class="k">def</span> <span class="nf">talburt_wang_index</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Talburt-Wang index of similarity of two partitions</span>

<span class="sd">        On sparse matrices, the resolving power of this measure asymptotically</span>
<span class="sd">        approaches that of assignment-based scores such as ``assignment_score``</span>
<span class="sd">        and ``split_join_similarity``, however on dense matrices this measure</span>
<span class="sd">        will not perform well due to its reliance on category cardinalities</span>
<span class="sd">        (how many types were seen) rather than on observation counts (how many</span>
<span class="sd">        instances of each type were seen).</span>

<span class="sd">        A relatively decent clustering::</span>

<span class="sd">            &gt;&gt;&gt; a = [ 1,  1,  1,  2,  2,  2,  2,  3,  3,  4]</span>
<span class="sd">            &gt;&gt;&gt; b = [43, 56, 56,  5, 36, 36, 36, 74, 74, 66]</span>
<span class="sd">            &gt;&gt;&gt; t = ContingencyTable.from_labels(a, b)</span>
<span class="sd">            &gt;&gt;&gt; round(t.talburt_wang_index(), 3)</span>
<span class="sd">            0.816</span>

<span class="sd">        Less good clustering (example from [1]_)::</span>

<span class="sd">            &gt;&gt;&gt; clusters = [[1, 1], [1, 1, 1, 1], [2, 3], [2, 2, 3, 3],</span>
<span class="sd">            ...             [3, 3, 4], [3, 4, 4, 4, 4, 4, 4, 4, 4, 4]]</span>
<span class="sd">            &gt;&gt;&gt; t = ContingencyTable.from_clusters(clusters)</span>
<span class="sd">            &gt;&gt;&gt; round(t.talburt_wang_index(), 2)</span>
<span class="sd">            0.49</span>

<span class="sd">        References</span>
<span class="sd">        ----------</span>

<span class="sd">        .. [1] `Talburt, J., Wang, R., Hess, K., &amp; Kuo, E. (2007). An algebraic</span>
<span class="sd">               approach to data quality metrics for entity resolution over large</span>
<span class="sd">               datasets.  Information quality management: Theory and</span>
<span class="sd">               applications, 1-22.</span>
<span class="sd">               &lt;http://www.igi-global.com/chapter/algebraic-approach-data-quality-metrics/23022&gt;`_</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">A_card</span><span class="p">,</span> <span class="n">B_card</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">V_card</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">_div</span><span class="p">(</span><span class="n">sqrt</span><span class="p">(</span><span class="n">A_card</span> <span class="o">*</span> <span class="n">B_card</span><span class="p">),</span> <span class="n">V_card</span><span class="p">)</span></div>

<div class="viewcode-block" id="ContingencyTable.muc_scores"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.ContingencyTable.muc_scores">[docs]</a>    <span class="k">def</span> <span class="nf">muc_scores</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;MUC similarity indices for coreference scoring</span>

<span class="sd">        Implemented after description in [1]_. The compound fscore-like metric</span>
<span class="sd">        has good resolving power on sparse models, similar to</span>
<span class="sd">        ``fowlkes_mallows`` (pairwise ``ochiai_coeff``), however it becomes</span>
<span class="sd">        useless on dense matrices as it relies on category cardinalities (how</span>
<span class="sd">        many types were seen) rather than on observation counts (how many</span>
<span class="sd">        instances of each type were seen).</span>

<span class="sd">        ::</span>

<span class="sd">            &gt;&gt;&gt; p1 = [x.split() for x in [&quot;A B C&quot;, &quot;D E F G&quot;]]</span>
<span class="sd">            &gt;&gt;&gt; p2 = [x.split() for x in [&quot;A B&quot;, &quot;C&quot;, &quot;D&quot;, &quot;E&quot;, &quot;F G&quot;]]</span>
<span class="sd">            &gt;&gt;&gt; cm = ClusteringMetrics.from_partitions(p1, p2)</span>
<span class="sd">            &gt;&gt;&gt; cm.muc_scores()[:2]</span>
<span class="sd">            (1.0, 0.4)</span>

<span class="sd">        Elements that are part of neither partition (in this case, E) are</span>
<span class="sd">        excluded from consideration::</span>

<span class="sd">            &gt;&gt;&gt; p1 = [x.split() for x in [&quot;A B&quot;, &quot;C&quot;, &quot;D&quot;, &quot;F G&quot;, &quot;H&quot;]]</span>
<span class="sd">            &gt;&gt;&gt; p2 = [x.split() for x in [&quot;A B&quot;, &quot;C D&quot;, &quot;F G H&quot;]]</span>
<span class="sd">            &gt;&gt;&gt; cm = ClusteringMetrics.from_partitions(p1, p2)</span>
<span class="sd">            &gt;&gt;&gt; cm.muc_scores()[:2]</span>
<span class="sd">            (0.5, 1.0)</span>

<span class="sd">        References</span>
<span class="sd">        ----------</span>

<span class="sd">        .. [1] `Vilain, M., Burger, J., Aberdeen, J., Connolly, D., &amp;</span>
<span class="sd">               Hirschman, L. (1995, November). A model-theoretic coreference</span>
<span class="sd">               scoring scheme. In Proceedings of the 6th conference on Message</span>
<span class="sd">               understanding (pp. 45-52).  Association for Computational</span>
<span class="sd">               Linguistics.</span>
<span class="sd">               &lt;http://www.aclweb.org/anthology/M/M95/M95-1005.pdf&gt;`_</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">A_card</span><span class="p">,</span> <span class="n">B_card</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">V_card</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="n">N</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">grand_total</span>

        <span class="n">recall</span> <span class="o">=</span> <span class="n">_div</span><span class="p">(</span><span class="n">N</span> <span class="o">-</span> <span class="n">V_card</span><span class="p">,</span>  <span class="n">N</span> <span class="o">-</span> <span class="n">A_card</span><span class="p">)</span>
        <span class="n">precision</span> <span class="o">=</span> <span class="n">_div</span><span class="p">(</span><span class="n">N</span> <span class="o">-</span> <span class="n">V_card</span><span class="p">,</span>  <span class="n">N</span> <span class="o">-</span> <span class="n">B_card</span><span class="p">)</span>
        <span class="n">fscore</span> <span class="o">=</span> <span class="n">harmonic_mean</span><span class="p">(</span><span class="n">recall</span><span class="p">,</span> <span class="n">precision</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">,</span> <span class="n">fscore</span></div>

<div class="viewcode-block" id="ContingencyTable.bc_metrics"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.ContingencyTable.bc_metrics">[docs]</a>    <span class="k">def</span> <span class="nf">bc_metrics</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;&#39;B-cubed&#39; precision, recall, and fscore</span>

<span class="sd">        As described in [1]_ and [2]_. Was extended to overlapping clusters in</span>
<span class="sd">        [3]_.  These metrics perform very similarly to normalized entropy</span>
<span class="sd">        metrics (homogeneity, completeness, V-measure).</span>

<span class="sd">        References</span>
<span class="sd">        ----------</span>

<span class="sd">        .. [1] `Bagga, A., &amp; Baldwin, B. (1998, August). Entity-based cross-</span>
<span class="sd">               document coreferencing using the vector space model. In</span>
<span class="sd">               Proceedings of the 36th Annual Meeting of the Association for</span>
<span class="sd">               Computational Linguistics and 17th International Conference on</span>
<span class="sd">               Computational Linguistics-Volume 1 (pp. 79-85).  Association for</span>
<span class="sd">               Computational Linguistics.</span>
<span class="sd">               &lt;https://aclweb.org/anthology/P/P98/P98-1012.pdf&gt;`_</span>

<span class="sd">        .. [2] `Bagga, A., &amp; Baldwin, B. (1998, May). Algorithms for scoring</span>
<span class="sd">               coreference chains. In The first international conference on</span>
<span class="sd">               language resources and evaluation workshop on linguistics</span>
<span class="sd">               coreference (Vol. 1, pp. 563-566).</span>
<span class="sd">               &lt;http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.47.5848&gt;`_</span>

<span class="sd">        .. [3] `Amig, E., Gonzalo, J., Artiles, J., &amp; Verdejo, F. (2009). A</span>
<span class="sd">               comparison of extrinsic clustering evaluation metrics based on</span>
<span class="sd">               formal constraints. Information retrieval, 12(4), 461-486.</span>
<span class="sd">               &lt;http://doi.org/10.1007/s10791-008-9066-8&gt;`_</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">precision</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="n">recall</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="k">for</span> <span class="n">rm</span><span class="p">,</span> <span class="n">cm</span><span class="p">,</span> <span class="n">observed</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">iter_vals_with_margins</span><span class="p">():</span>
            <span class="n">precision</span> <span class="o">+=</span> <span class="p">(</span><span class="n">observed</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">cm</span><span class="p">)</span>
            <span class="n">recall</span> <span class="o">+=</span> <span class="p">(</span><span class="n">observed</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">rm</span><span class="p">)</span>
        <span class="n">N</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">grand_total</span>
        <span class="n">precision</span> <span class="o">=</span> <span class="n">_div</span><span class="p">(</span><span class="n">precision</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span>
        <span class="n">recall</span> <span class="o">=</span> <span class="n">_div</span><span class="p">(</span><span class="n">recall</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span>
        <span class="n">fscore</span> <span class="o">=</span> <span class="n">harmonic_mean</span><span class="p">(</span><span class="n">recall</span><span class="p">,</span> <span class="n">precision</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">,</span> <span class="n">fscore</span></div></div>


<div class="viewcode-block" id="ClusteringMetrics"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.ClusteringMetrics">[docs]</a><span class="k">class</span> <span class="nc">ClusteringMetrics</span><span class="p">(</span><span class="n">ContingencyTable</span><span class="p">):</span>

    <span class="sd">&quot;&quot;&quot;Provides external clustering evaluation metrics</span>

<span class="sd">    A subclass of ContingencyTable that builds a pairwise co-association matrix</span>
<span class="sd">    for clustering comparisons.</span>

<span class="sd">    ::</span>

<span class="sd">        &gt;&gt;&gt; Y1 = {(1, 2, 3), (4, 5, 6)}</span>
<span class="sd">        &gt;&gt;&gt; Y2 = {(1, 2), (3, 4, 5), (6,)}</span>
<span class="sd">        &gt;&gt;&gt; cm = ClusteringMetrics.from_partitions(Y1, Y2)</span>
<span class="sd">        &gt;&gt;&gt; cm.split_join_similarity(model=None)</span>
<span class="sd">        0.75</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="n">ContingencyTable</span><span class="o">.</span><span class="n">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_pairwise</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_pairwise_models</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">pairwise</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Confusion matrix on all pair assignments from two partitions</span>

<span class="sd">        A partition of N is a set of disjoint clusters s.t. every point in N</span>
<span class="sd">        belongs to one and only one cluster and every cluster consists of at</span>
<span class="sd">        least one point. Given two partitions A and B and a co-occurrence</span>
<span class="sd">        matrix of point pairs,</span>

<span class="sd">        == =============================================================</span>
<span class="sd">        TP count of pairs found in the same partition in both A and B</span>
<span class="sd">        FP count of pairs found in the same partition in A but not in B</span>
<span class="sd">        FN count of pairs found in the same partition in B but not in A</span>
<span class="sd">        TN count of pairs in different partitions in both A and B</span>
<span class="sd">        == =============================================================</span>

<span class="sd">        Note that although the resulting confusion matrix has the form of a</span>
<span class="sd">        correlation table for two binary variables, it is not symmetric if the</span>
<span class="sd">        original partitions are not symmetric.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">pairwise</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pairwise</span>
        <span class="k">if</span> <span class="n">pairwise</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">actual_positives</span> <span class="o">=</span> <span class="n">fsum_pairs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">iter_row_totals</span><span class="p">())</span>
            <span class="n">called_positives</span> <span class="o">=</span> <span class="n">fsum_pairs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">iter_col_totals</span><span class="p">())</span>
            <span class="n">TP</span> <span class="o">=</span> <span class="n">fsum_pairs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">itervalues</span><span class="p">())</span>
            <span class="n">FN</span> <span class="o">=</span> <span class="n">actual_positives</span> <span class="o">-</span> <span class="n">TP</span>
            <span class="n">FP</span> <span class="o">=</span> <span class="n">called_positives</span> <span class="o">-</span> <span class="n">TP</span>
            <span class="n">TN</span> <span class="o">=</span> <span class="n">fnum_pairs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">grand_total</span><span class="p">)</span> <span class="o">-</span> <span class="n">TP</span> <span class="o">-</span> <span class="n">FP</span> <span class="o">-</span> <span class="n">FN</span>
            <span class="n">pairwise</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pairwise</span> <span class="o">=</span> <span class="n">ConfusionMatrix2</span><span class="o">.</span><span class="n">from_ccw</span><span class="p">(</span><span class="n">TP</span><span class="p">,</span> <span class="n">FP</span><span class="p">,</span> <span class="n">TN</span><span class="p">,</span> <span class="n">FN</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">pairwise</span>

<div class="viewcode-block" id="ClusteringMetrics.get_score"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.ClusteringMetrics.get_score">[docs]</a>    <span class="k">def</span> <span class="nf">get_score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">scoring_method</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Evaluate specified scoring method</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">method</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">scoring_method</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
            <span class="n">method</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pairwise</span><span class="p">,</span> <span class="n">scoring_method</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">method</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>

<div class="viewcode-block" id="ClusteringMetrics.adjusted_rand_index"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.ClusteringMetrics.adjusted_rand_index">[docs]</a>    <span class="k">def</span> <span class="nf">adjusted_rand_index</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Rand score (accuracy) corrected for chance</span>

<span class="sd">        This is a memory-efficient replacement for a similar Scikit-Learn</span>
<span class="sd">        function.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">pairwise</span><span class="o">.</span><span class="n">kappa</span><span class="p">()</span></div>

<div class="viewcode-block" id="ClusteringMetrics.rand_index"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.ClusteringMetrics.rand_index">[docs]</a>    <span class="k">def</span> <span class="nf">rand_index</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Pairwise accuracy (uncorrected for chance)</span>

<span class="sd">        Don&#39;t use this metric; it is only added here as the &quot;worst reference&quot;</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">pairwise</span><span class="o">.</span><span class="n">accuracy</span><span class="p">()</span></div>

<div class="viewcode-block" id="ClusteringMetrics.fowlkes_mallows"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.ClusteringMetrics.fowlkes_mallows">[docs]</a>    <span class="k">def</span> <span class="nf">fowlkes_mallows</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Fowlkes-Mallows index for partition comparison</span>

<span class="sd">        Defined as the Ochiai coefficient on the pairwise matrix</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">pairwise</span><span class="o">.</span><span class="n">ochiai_coeff</span><span class="p">()</span></div>

<div class="viewcode-block" id="ClusteringMetrics.adjusted_fowlkes_mallows"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.ClusteringMetrics.adjusted_fowlkes_mallows">[docs]</a>    <span class="k">def</span> <span class="nf">adjusted_fowlkes_mallows</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Fowlkes-Mallows index adjusted for chance</span>

<span class="sd">        Adjustmend for chance done by subtracting the expected (Model 3)</span>
<span class="sd">        pairwise matrix from the actual one. This coefficient appears to be</span>
<span class="sd">        uniformly more powerful than the unadjusted version. Compared to ARI</span>
<span class="sd">        and product-moment correlation coefficients, this index is generally</span>
<span class="sd">        less powerful except in particularly poorly specified cases, e.g.</span>
<span class="sd">        clusters of unequal size sampled with high error rate from a large</span>
<span class="sd">        population.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">pairwise</span><span class="o">.</span><span class="n">ochiai_coeff_adj</span><span class="p">()</span></div>

<div class="viewcode-block" id="ClusteringMetrics.mirkin_match_coeff"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.ClusteringMetrics.mirkin_match_coeff">[docs]</a>    <span class="k">def</span> <span class="nf">mirkin_match_coeff</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Equivalence match (similarity) coefficient</span>

<span class="sd">        Derivation of distance variant described in [1]_. This measure is</span>
<span class="sd">        nearly identical to pairwise unadjusted Rand index, as can be seen from</span>
<span class="sd">        the definition (Mirkin match formula uses square while pairwise</span>
<span class="sd">        accuracy uses n choose 2).</span>

<span class="sd">        ::</span>

<span class="sd">            &gt;&gt;&gt; C3 = [{1, 2, 3, 4}, {5, 6, 7, 8, 9, 10}, {11, 12, 13, 14, 15, 16}]</span>
<span class="sd">            &gt;&gt;&gt; C4 = [{1, 2, 3, 4}, {5, 6, 7, 8, 9, 10, 11, 12}, {13, 14, 15, 16}]</span>
<span class="sd">            &gt;&gt;&gt; t = ClusteringMetrics.from_partitions(C3, C4)</span>
<span class="sd">            &gt;&gt;&gt; t.mirkin_match_coeff(normalize=False)</span>
<span class="sd">            216.0</span>

<span class="sd">        References</span>
<span class="sd">        ----------</span>

<span class="sd">        .. [1] `Mirkin, B (1996). Mathematical Classification and Clustering.</span>
<span class="sd">               Kluwer Academic Press: Boston-Dordrecht.</span>
<span class="sd">               &lt;http://www.amazon.com/dp/0792341597&gt;`_</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">max_score</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">grand_total</span> <span class="o">**</span> <span class="mi">2</span>
        <span class="n">score</span> <span class="o">=</span> <span class="n">max_score</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">mirkin_mismatch_coeff</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">normalize</span><span class="p">:</span>
            <span class="n">score</span> <span class="o">=</span> <span class="n">_div</span><span class="p">(</span><span class="n">score</span><span class="p">,</span> <span class="n">max_score</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">score</span></div>

<div class="viewcode-block" id="ClusteringMetrics.mirkin_mismatch_coeff"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.ClusteringMetrics.mirkin_mismatch_coeff">[docs]</a>    <span class="k">def</span> <span class="nf">mirkin_mismatch_coeff</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Equivalence mismatch (distance) coefficient</span>

<span class="sd">        Direct formulation (without the pairwise abstraction):</span>

<span class="sd">        .. math::</span>

<span class="sd">            M = \\sum_{i=1}^{R} r_{i}^2 + \\sum_{j=1}^{C} c_{j}^2 - \\sum_{i=1}^{R}\\sum_{j=1}^{C} n_{ij}^2,</span>

<span class="sd">        where :math:`r` and :math:`c` are row and column margins, respectively,</span>
<span class="sd">        with :math:`R` and :math:`C` cardinalities.</span>

<span class="sd">        ::</span>

<span class="sd">            &gt;&gt;&gt; C1 = [{1, 2, 3, 4, 5, 6, 7, 8}, {9, 10, 11, 12, 13, 14, 15, 16}]</span>
<span class="sd">            &gt;&gt;&gt; C2 = [{1, 2, 3, 4, 5, 6, 7, 8, 9, 10}, {11, 12, 13, 14, 15, 16}]</span>
<span class="sd">            &gt;&gt;&gt; t = ClusteringMetrics.from_partitions(C1, C2)</span>
<span class="sd">            &gt;&gt;&gt; t.mirkin_mismatch_coeff(normalize=False)</span>
<span class="sd">            56.0</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">score</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pairwise</span><span class="o">.</span><span class="n">FN</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">pairwise</span><span class="o">.</span><span class="n">FP</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">normalize</span><span class="p">:</span>
            <span class="n">score</span> <span class="o">=</span> <span class="n">_div</span><span class="p">(</span><span class="n">score</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">grand_total</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">score</span></div></div>


<span class="n">confmat2_type</span> <span class="o">=</span> <span class="n">namedtuple</span><span class="p">(</span><span class="s2">&quot;ConfusionMatrix2&quot;</span><span class="p">,</span> <span class="s2">&quot;TP FP TN FN&quot;</span><span class="p">)</span>


<div class="viewcode-block" id="ConfusionMatrix2"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.ConfusionMatrix2">[docs]</a><span class="k">class</span> <span class="nc">ConfusionMatrix2</span><span class="p">(</span><span class="n">ContingencyTable</span><span class="p">,</span> <span class="n">OrderedCrossTab</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;A confusion matrix (2x2 contingency table)</span>

<span class="sd">    For a binary variable (where one is measuring either presence vs absence of</span>
<span class="sd">    a particular feature), a confusion matrix where the ground truth levels are</span>
<span class="sd">    rows looks like this::</span>

<span class="sd">        &gt;&gt;&gt; cm = ConfusionMatrix2(TP=20, FN=31, FP=14, TN=156)</span>
<span class="sd">        &gt;&gt;&gt; cm</span>
<span class="sd">        ConfusionMatrix2(rows=[[20, 31], [14, 156]])</span>
<span class="sd">        &gt;&gt;&gt; cm.to_array()</span>
<span class="sd">        array([[ 20,  31],</span>
<span class="sd">               [ 14, 156]])</span>

<span class="sd">    For a nominal variable, the negative class becomes a distinct label, and</span>
<span class="sd">    TP/FP/FN/TN terminology does not apply, although the algorithms should work</span>
<span class="sd">    the same way (with the obvious distinction that different assumptions will</span>
<span class="sd">    be made). For a convenient reference about some of the attributes and</span>
<span class="sd">    methods defined here see [1]_.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>

<span class="sd">    TP :</span>
<span class="sd">        True positive count</span>
<span class="sd">    FP :</span>
<span class="sd">        False positive count</span>
<span class="sd">    TN :</span>
<span class="sd">        True negative count</span>
<span class="sd">    FN :</span>
<span class="sd">        False negative count</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>

<span class="sd">    .. [1] `Wikipedia entry for Confusion Matrix</span>
<span class="sd">            &lt;https://en.wikipedia.org/wiki/Confusion_matrix&gt;`_</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="s2">&quot;ConfusionMatrix2(rows=</span><span class="si">%s</span><span class="s2">)&quot;</span> <span class="o">%</span> <span class="nb">repr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">to_rows</span><span class="p">())</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">TP</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">FN</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">FP</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">TN</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">rows</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">rows</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">rows</span> <span class="o">=</span> <span class="p">((</span><span class="n">TP</span><span class="p">,</span> <span class="n">FN</span><span class="p">),</span> <span class="p">(</span><span class="n">FP</span><span class="p">,</span> <span class="n">TN</span><span class="p">))</span>
        <span class="n">ContingencyTable</span><span class="o">.</span><span class="n">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rows</span><span class="o">=</span><span class="n">rows</span><span class="p">)</span>

<div class="viewcode-block" id="ConfusionMatrix2.lform"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.ConfusionMatrix2.lform">[docs]</a>    <span class="k">def</span> <span class="nf">lform</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Factory creating L-form version of current table</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">a</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_ccw</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">b</span> <span class="o">&lt;</span> <span class="n">c</span><span class="p">:</span>
            <span class="n">a</span> <span class="o">+=</span> <span class="n">b</span>
            <span class="n">b</span> <span class="o">-=</span> <span class="n">b</span>
            <span class="n">c</span> <span class="o">-=</span> <span class="n">b</span>
            <span class="n">d</span> <span class="o">+=</span> <span class="n">b</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">a</span> <span class="o">+=</span> <span class="n">c</span>
            <span class="n">b</span> <span class="o">-=</span> <span class="n">c</span>
            <span class="n">c</span> <span class="o">-=</span> <span class="n">c</span>
            <span class="n">d</span> <span class="o">+=</span> <span class="n">c</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">__class__</span><span class="o">.</span><span class="n">from_ccw</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span></div>

    <span class="nd">@classmethod</span>
<div class="viewcode-block" id="ConfusionMatrix2.from_sets"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.ConfusionMatrix2.from_sets">[docs]</a>    <span class="k">def</span> <span class="nf">from_sets</span><span class="p">(</span><span class="n">cls</span><span class="p">,</span> <span class="n">set1</span><span class="p">,</span> <span class="n">set2</span><span class="p">,</span> <span class="n">universe_size</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Instantiate from two sets</span>

<span class="sd">        Accepts an optional universe_size parameter which allows us to take into</span>
<span class="sd">        account TN class and use probability-based similarity metrics.  Most of</span>
<span class="sd">        the time, however, set comparisons are performed ignoring this parameter</span>
<span class="sd">        and relying instead on non-probabilistic indices such as Jaccard&#39;s or</span>
<span class="sd">        Dice.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">set1</span><span class="p">,</span> <span class="n">Set</span><span class="p">):</span>
            <span class="n">set1</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">set1</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">set2</span><span class="p">,</span> <span class="n">Set</span><span class="p">):</span>
            <span class="n">set2</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">set2</span><span class="p">)</span>
        <span class="n">TP</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">set1</span> <span class="o">&amp;</span> <span class="n">set2</span><span class="p">)</span>
        <span class="n">FP</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">set2</span><span class="p">)</span> <span class="o">-</span> <span class="n">TP</span>
        <span class="n">FN</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">set1</span><span class="p">)</span> <span class="o">-</span> <span class="n">TP</span>
        <span class="k">if</span> <span class="n">universe_size</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">TN</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">TN</span> <span class="o">=</span> <span class="n">universe_size</span> <span class="o">-</span> <span class="n">TP</span> <span class="o">-</span> <span class="n">FP</span> <span class="o">-</span> <span class="n">FN</span>
            <span class="k">if</span> <span class="n">TN</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;universe_size must be at least as large as set union&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">cls</span><span class="p">(</span><span class="n">TP</span><span class="p">,</span> <span class="n">FN</span><span class="p">,</span> <span class="n">FP</span><span class="p">,</span> <span class="n">TN</span><span class="p">)</span></div>

    <span class="nd">@classmethod</span>
<div class="viewcode-block" id="ConfusionMatrix2.from_random_counts"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.ConfusionMatrix2.from_random_counts">[docs]</a>    <span class="k">def</span> <span class="nf">from_random_counts</span><span class="p">(</span><span class="n">cls</span><span class="p">,</span> <span class="n">low</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Instantiate from random values</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">cls</span><span class="p">(</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="n">low</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="n">high</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,)))</span></div>

    <span class="nd">@classmethod</span>
<div class="viewcode-block" id="ConfusionMatrix2.from_ccw"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.ConfusionMatrix2.from_ccw">[docs]</a>    <span class="k">def</span> <span class="nf">from_ccw</span><span class="p">(</span><span class="n">cls</span><span class="p">,</span> <span class="n">TP</span><span class="p">,</span> <span class="n">FP</span><span class="p">,</span> <span class="n">TN</span><span class="p">,</span> <span class="n">FN</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Instantiate from counter-clockwise form of TP FP TN FN</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">cls</span><span class="p">(</span><span class="n">TP</span><span class="p">,</span> <span class="n">FN</span><span class="p">,</span> <span class="n">FP</span><span class="p">,</span> <span class="n">TN</span><span class="p">)</span></div>

<div class="viewcode-block" id="ConfusionMatrix2.to_ccw"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.ConfusionMatrix2.to_ccw">[docs]</a>    <span class="k">def</span> <span class="nf">to_ccw</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Convert to counter-clockwise form of TP FP TN FN</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">confmat2_type</span><span class="p">(</span><span class="n">TP</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">TP</span><span class="p">,</span> <span class="n">FP</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">FP</span><span class="p">,</span> <span class="n">TN</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">TN</span><span class="p">,</span> <span class="n">FN</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">FN</span><span class="p">)</span></div>

<div class="viewcode-block" id="ConfusionMatrix2.get_score"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.ConfusionMatrix2.get_score">[docs]</a>    <span class="k">def</span> <span class="nf">get_score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">scoring_method</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Evaluate specified scoring method</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">method</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">scoring_method</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">method</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">TP</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">rows</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">FN</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">rows</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">FP</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">rows</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">TN</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">rows</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>

<div class="viewcode-block" id="ConfusionMatrix2.hypergeometric"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.ConfusionMatrix2.hypergeometric">[docs]</a>    <span class="k">def</span> <span class="nf">hypergeometric</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Hypergeometric association score</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">covsign</span> <span class="o">=</span> <span class="n">copysign</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">covar</span><span class="p">())</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">pvalue</span> <span class="o">=</span> <span class="n">fisher_exact</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">to_array</span><span class="p">())</span>
        <span class="k">return</span> <span class="n">covsign</span> <span class="o">*</span> <span class="p">(</span><span class="o">-</span><span class="n">_log</span><span class="p">(</span><span class="n">pvalue</span><span class="p">))</span></div>

<div class="viewcode-block" id="ConfusionMatrix2.ACC"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.ConfusionMatrix2.ACC">[docs]</a>    <span class="k">def</span> <span class="nf">ACC</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Accuracy (Rand Index)</span>

<span class="sd">        Synonyms: Simple Matching Coefficient, Rand Index</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">_div</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">TP</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">TN</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">grand_total</span><span class="p">)</span></div>

<div class="viewcode-block" id="ConfusionMatrix2.PPV"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.ConfusionMatrix2.PPV">[docs]</a>    <span class="k">def</span> <span class="nf">PPV</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Positive Predictive Value (Precision)</span>

<span class="sd">        Synonyms: precision, frequency of hits, post agreement, success ratio,</span>
<span class="sd">        correct alarm ratio</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">_div</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">TP</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">TP</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">FP</span><span class="p">)</span></div>

<div class="viewcode-block" id="ConfusionMatrix2.NPV"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.ConfusionMatrix2.NPV">[docs]</a>    <span class="k">def</span> <span class="nf">NPV</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Negative Predictive Value</span>

<span class="sd">        Synonyms: frequency of correct null forecasts</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">_div</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">TN</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">TN</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">FN</span><span class="p">)</span></div>

<div class="viewcode-block" id="ConfusionMatrix2.TPR"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.ConfusionMatrix2.TPR">[docs]</a>    <span class="k">def</span> <span class="nf">TPR</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;True Positive Rate (Recall, Sensitivity)</span>

<span class="sd">        Synonyms: recall, sensitivity, hit rate, probability of detection,</span>
<span class="sd">        prefigurance</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">_div</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">TP</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">TP</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">FN</span><span class="p">)</span></div>

<div class="viewcode-block" id="ConfusionMatrix2.FPR"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.ConfusionMatrix2.FPR">[docs]</a>    <span class="k">def</span> <span class="nf">FPR</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;False Positive Rate</span>

<span class="sd">        Synonyms: fallout</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">_div</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">FP</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">TN</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">FP</span><span class="p">)</span></div>

<div class="viewcode-block" id="ConfusionMatrix2.TNR"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.ConfusionMatrix2.TNR">[docs]</a>    <span class="k">def</span> <span class="nf">TNR</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;True Negative Rate (Specificity)</span>

<span class="sd">        Synonyms: specificity</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">_div</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">TN</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">FP</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">TN</span><span class="p">)</span></div>

<div class="viewcode-block" id="ConfusionMatrix2.FNR"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.ConfusionMatrix2.FNR">[docs]</a>    <span class="k">def</span> <span class="nf">FNR</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;False Negative Rate</span>

<span class="sd">        Synonyms: miss rate, frequency of misses</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">_div</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">FN</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">TP</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">FN</span><span class="p">)</span></div>

<div class="viewcode-block" id="ConfusionMatrix2.FDR"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.ConfusionMatrix2.FDR">[docs]</a>    <span class="k">def</span> <span class="nf">FDR</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;False discovery rate</span>

<span class="sd">        Synonyms: false alarm ratio, probability of false alarm</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">_div</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">FP</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">TP</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">FP</span><span class="p">)</span></div>

<div class="viewcode-block" id="ConfusionMatrix2.FOR"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.ConfusionMatrix2.FOR">[docs]</a>    <span class="k">def</span> <span class="nf">FOR</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;False omission rate</span>

<span class="sd">        Synonyms: detection failure ratio, miss ratio</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">_div</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">FN</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">TN</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">FN</span><span class="p">)</span></div>

<div class="viewcode-block" id="ConfusionMatrix2.PLL"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.ConfusionMatrix2.PLL">[docs]</a>    <span class="k">def</span> <span class="nf">PLL</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Positive likelihood ratio</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">_div</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">TPR</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">FPR</span><span class="p">())</span></div>

<div class="viewcode-block" id="ConfusionMatrix2.NLL"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.ConfusionMatrix2.NLL">[docs]</a>    <span class="k">def</span> <span class="nf">NLL</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Negative likelihood ratio</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">_div</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">FNR</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">TNR</span><span class="p">())</span></div>

<div class="viewcode-block" id="ConfusionMatrix2.DOR"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.ConfusionMatrix2.DOR">[docs]</a>    <span class="k">def</span> <span class="nf">DOR</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Diagnostics odds ratio</span>

<span class="sd">        Defined as</span>

<span class="sd">        .. math::</span>

<span class="sd">            DOR = \\frac{PLL}{NLL}.</span>

<span class="sd">        Odds ratio has a number of interesting/desirable properties, however</span>
<span class="sd">        its one peculiarity that leaves us looking for an alternative measure</span>
<span class="sd">        is that on L-shaped matrices like,</span>

<span class="sd">        .. math::</span>

<span class="sd">            \\begin{matrix} 77 &amp; 0 \\\\ 5 &amp; 26 \\end{matrix}</span>

<span class="sd">        its value will be infinity.</span>

<span class="sd">        Also known as: crude odds ratio, Mantel-Haenszel estimate.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">a</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_ccw</span><span class="p">()</span>
        <span class="n">ad</span><span class="p">,</span> <span class="n">bc</span> <span class="o">=</span> <span class="n">a</span> <span class="o">*</span> <span class="n">d</span><span class="p">,</span> <span class="n">b</span> <span class="o">*</span> <span class="n">c</span>
        <span class="k">return</span> <span class="n">_div</span><span class="p">(</span><span class="n">ad</span><span class="p">,</span> <span class="n">bc</span><span class="p">)</span></div>

<div class="viewcode-block" id="ConfusionMatrix2.fscore"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.ConfusionMatrix2.fscore">[docs]</a>    <span class="k">def</span> <span class="nf">fscore</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;F-score</span>

<span class="sd">        As beta tends to infinity, F-score will approach recall.  As beta tends</span>
<span class="sd">        to zero, F-score will approach precision. A similarity coefficient that</span>
<span class="sd">        uses a similar definition is called Dice coefficient.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        dice_coeff</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">harmonic_mean_weighted</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">precision</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">recall</span><span class="p">(),</span> <span class="n">beta</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span></div>

<div class="viewcode-block" id="ConfusionMatrix2.dice_coeff"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.ConfusionMatrix2.dice_coeff">[docs]</a>    <span class="k">def</span> <span class="nf">dice_coeff</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Dice similarity (Nei-Li coefficient)</span>

<span class="sd">        This is the same as F1-score, but calculated slightly differently here.</span>
<span class="sd">        Note that Dice can be zero if total number of positives is zero, but</span>
<span class="sd">        F-score is undefined in that case (because recall is undefined).</span>

<span class="sd">        When adjusted for chance, this coefficient becomes identical to</span>
<span class="sd">        ``kappa`` [1]_.</span>

<span class="sd">        Since this coefficient is monotonic with respect to Jaccard and Sokal</span>
<span class="sd">        Sneath coefficients, its resolving power is identical to that of the</span>
<span class="sd">        other two.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        jaccard_coeff, sokal_sneath_coeff</span>

<span class="sd">        References</span>
<span class="sd">        ----------</span>

<span class="sd">        .. [1] `Albatineh, A. N., Niewiadomska-Bugaj, M., &amp; Mihalko, D. (2006).</span>
<span class="sd">               On similarity indices and correction for chance agreement.</span>
<span class="sd">               Journal of Classification, 23(2), 301-313.</span>
<span class="sd">               &lt;http://doi.org/10.1007/s00357-006-0017-z&gt;`_</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">a</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_ccw</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">_div</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">a</span><span class="p">,</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span> <span class="o">+</span> <span class="n">c</span><span class="p">)</span></div>

<div class="viewcode-block" id="ConfusionMatrix2.overlap_coeff"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.ConfusionMatrix2.overlap_coeff">[docs]</a>    <span class="k">def</span> <span class="nf">overlap_coeff</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Overlap coefficient (Szymkiewicz-Simpson coefficient)</span>

<span class="sd">        Can be obtained by standardizing Dice or Ochiai coefficients by their</span>
<span class="sd">        maximum possible value given fixed marginals. Not corrected for chance.</span>

<span class="sd">        Note that :math:`min(p_1, p_2)` is equal to the maximum value of</span>
<span class="sd">        :math:`a` given fixed marginals.</span>

<span class="sd">        When adjusted for chance, this coefficient turns into Loevinger&#39;s H.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        loevinger_coeff</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">a</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_ccw</span><span class="p">()</span>
        <span class="n">p1</span><span class="p">,</span> <span class="n">p2</span> <span class="o">=</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span><span class="p">,</span> <span class="n">a</span> <span class="o">+</span> <span class="n">c</span>
        <span class="n">a_max</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">p1</span><span class="p">,</span> <span class="n">p2</span><span class="p">)</span>
        <span class="k">return</span> <span class="mf">0.0</span> <span class="k">if</span> <span class="n">a_max</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">_div</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">a_max</span><span class="p">)</span></div>

<div class="viewcode-block" id="ConfusionMatrix2.jaccard_coeff"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.ConfusionMatrix2.jaccard_coeff">[docs]</a>    <span class="k">def</span> <span class="nf">jaccard_coeff</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Jaccard similarity coefficient</span>

<span class="sd">        Jaccard coefficient has an interesting property in that in L-shaped</span>
<span class="sd">        matrices where either FP or FN are close to zero, its scale becomes</span>
<span class="sd">        equivalent to the scale of either recall or precision respectively.</span>

<span class="sd">        Since this coefficient is monotonic with respect to Dice (F-score) and</span>
<span class="sd">        Sokal Sneath coefficients, its resolving power is identical to that of</span>
<span class="sd">        the other two.</span>

<span class="sd">        Jaccard index does not belong to the L-family of association indices</span>
<span class="sd">        and thus cannot be adjusted for chance by subtracting the its value</span>
<span class="sd">        under fixed-margin null model. Instead, its expectation must be</span>
<span class="sd">        calculated, for which no analytical solution exists [1]_.</span>

<span class="sd">        Synonyms: critical success index</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        dice_coeff, sokal_sneath_coeff</span>

<span class="sd">        References</span>
<span class="sd">        ----------</span>

<span class="sd">        .. [1] `Albatineh, A. N., &amp; Niewiadomska-Bugaj, M. (2011). Correcting</span>
<span class="sd">               Jaccard and other similarity indices for chance agreement in</span>
<span class="sd">               cluster analysis. Advances in Data Analysis and Classification,</span>
<span class="sd">               5(3), 179-200.</span>
<span class="sd">               &lt;http://doi.org/10.1007/s11634-011-0090-y&gt;`_</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">a</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_ccw</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">_div</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span> <span class="o">+</span> <span class="n">c</span><span class="p">)</span></div>

<div class="viewcode-block" id="ConfusionMatrix2.ochiai_coeff_adj"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.ConfusionMatrix2.ochiai_coeff_adj">[docs]</a>    <span class="k">def</span> <span class="nf">ochiai_coeff_adj</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Ochiai coefficient adjusted for chance</span>

<span class="sd">        This index is nearly identical to Mattthews&#39; Correlation Coefficient,</span>
<span class="sd">        which should be used instead.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        matthews_corr, ochiai_coeff</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">a</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_ccw</span><span class="p">()</span>
        <span class="n">p1</span><span class="p">,</span> <span class="n">p2</span> <span class="o">=</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span><span class="p">,</span> <span class="n">a</span> <span class="o">+</span> <span class="n">c</span>
        <span class="n">n</span> <span class="o">=</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span> <span class="o">+</span> <span class="n">c</span> <span class="o">+</span> <span class="n">d</span>

        <span class="k">if</span> <span class="n">n</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
        <span class="k">elif</span> <span class="n">a</span> <span class="o">==</span> <span class="n">n</span> <span class="ow">or</span> <span class="n">d</span> <span class="o">==</span> <span class="n">n</span><span class="p">:</span>
            <span class="c1"># only one (diagonal) cell is non-zero</span>
            <span class="k">return</span> <span class="mf">0.5</span>
        <span class="k">elif</span> <span class="n">p1</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">p2</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># first row or column is zero, second non-zero</span>
            <span class="k">return</span> <span class="mf">0.0</span>

        <span class="n">p1_p2</span> <span class="o">=</span> <span class="n">p1</span> <span class="o">*</span> <span class="n">p2</span>
        <span class="n">numer</span> <span class="o">=</span> <span class="n">n</span> <span class="o">*</span> <span class="n">a</span> <span class="o">-</span> <span class="n">p1_p2</span>
        <span class="n">denom</span> <span class="o">=</span> <span class="n">n</span> <span class="o">*</span> <span class="n">sqrt</span><span class="p">(</span><span class="n">p1_p2</span><span class="p">)</span> <span class="o">-</span> <span class="n">p1_p2</span>
        <span class="k">return</span> <span class="n">_div</span><span class="p">(</span><span class="n">numer</span><span class="p">,</span> <span class="n">denom</span><span class="p">)</span></div>

<div class="viewcode-block" id="ConfusionMatrix2.ochiai_coeff"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.ConfusionMatrix2.ochiai_coeff">[docs]</a>    <span class="k">def</span> <span class="nf">ochiai_coeff</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Ochiai similarity coefficient (Fowlkes-Mallows)</span>

<span class="sd">        One interpretation of this coefficient that it is equal to the</span>
<span class="sd">        geometric mean of the conditional probability of an element (in the</span>
<span class="sd">        case of pairwise clustering comparison, a pair of elements) belonging</span>
<span class="sd">        to the same cluster given that they belong to the same class [1]_.</span>

<span class="sd">        This coefficient is in the L-family, and thus it can be corrected for</span>
<span class="sd">        chance by subtracting its value under fixed-margin null model. The</span>
<span class="sd">        resulting adjusted index is very close to, but not the same as,</span>
<span class="sd">        Matthews Correlation Coefficient. Empirically, the discriminating power</span>
<span class="sd">        of the adjusted coefficient is equal to that of Matthews&#39; Correlation</span>
<span class="sd">        Coefficient to within rounding error.</span>

<span class="sd">        Synonyms: Cosine Similarity, Fowlkes-Mallows Index</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        jaccard_coeff, dice_coeff, ochiai_coeff_adj</span>

<span class="sd">        References</span>
<span class="sd">        ----------</span>

<span class="sd">        .. [1] `Ramirez, E. H., Brena, R., Magatti, D., &amp; Stella, F. (2012).</span>
<span class="sd">               Topic model validation. Neurocomputing, 76(1), 125-133.</span>
<span class="sd">               &lt;http://dx.doi.org/10.1016/j.neucom.2011.04.032&gt;`_</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">a</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_ccw</span><span class="p">()</span>
        <span class="n">p1</span><span class="p">,</span> <span class="n">p2</span> <span class="o">=</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span><span class="p">,</span> <span class="n">a</span> <span class="o">+</span> <span class="n">c</span>
        <span class="k">if</span> <span class="n">a</span> <span class="o">==</span> <span class="n">b</span> <span class="o">==</span> <span class="n">c</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
        <span class="k">elif</span> <span class="n">a</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="mf">0.0</span>
        <span class="k">return</span> <span class="n">_div</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">sqrt</span><span class="p">(</span><span class="n">p1</span> <span class="o">*</span> <span class="n">p2</span><span class="p">))</span></div>

<div class="viewcode-block" id="ConfusionMatrix2.sokal_sneath_coeff"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.ConfusionMatrix2.sokal_sneath_coeff">[docs]</a>    <span class="k">def</span> <span class="nf">sokal_sneath_coeff</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Sokal and Sneath similarity index</span>

<span class="sd">        In a 2x2 matrix</span>

<span class="sd">        .. math::</span>

<span class="sd">            \\begin{matrix} a &amp; b \\\\ c &amp; d \\end{matrix}</span>

<span class="sd">        Dice places more weight on :math:`a` component, Jaccard places equal</span>
<span class="sd">        weight on :math:`a` and :math:`b + c`, while Sokal and Sneath places</span>
<span class="sd">        more weight on :math:`b + c`.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        dice_coeff, jaccard_coeff</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">a</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_ccw</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">_div</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">a</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">b</span> <span class="o">+</span> <span class="n">c</span><span class="p">))</span></div>

<div class="viewcode-block" id="ConfusionMatrix2.prevalence_index"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.ConfusionMatrix2.prevalence_index">[docs]</a>    <span class="k">def</span> <span class="nf">prevalence_index</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Prevalence</span>

<span class="sd">        In interrater agreement studies, prevalence is high when the proportion</span>
<span class="sd">        of agreements on the positive classification differs from that of the</span>
<span class="sd">        negative classification.  Example of a confusion matrix with high</span>
<span class="sd">        prevalence of negative response (note that this happens regardless of</span>
<span class="sd">        which rater we look at):</span>

<span class="sd">        .. math::</span>

<span class="sd">            \\begin{matrix} 3 &amp; 27 \\\\ 28 &amp; 132 \\end{matrix}</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>

<span class="sd">        bias_index</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">_div</span><span class="p">(</span><span class="nb">abs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">TP</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">TN</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">grand_total</span><span class="p">)</span></div>

<div class="viewcode-block" id="ConfusionMatrix2.frequency_bias"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.ConfusionMatrix2.frequency_bias">[docs]</a>    <span class="k">def</span> <span class="nf">frequency_bias</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Frequency bias</span>

<span class="sd">        How much more often is rater B is predicting TP</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">_div</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">TP</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">FP</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">TP</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">FN</span><span class="p">)</span></div>

<div class="viewcode-block" id="ConfusionMatrix2.bias_index"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.ConfusionMatrix2.bias_index">[docs]</a>    <span class="k">def</span> <span class="nf">bias_index</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Bias Index</span>

<span class="sd">        In interrater agreement studies, bias is the extent to which the raters</span>
<span class="sd">        disagree on the positive-negative ratio of the binary variable studied.</span>
<span class="sd">        Example of a confusion matrix with high bias of rater A (represented by</span>
<span class="sd">        rows) towards negative rating:</span>

<span class="sd">        .. math::</span>

<span class="sd">            \\begin{matrix} 17 &amp; 14 \\\\ 78 &amp; 81 \\end{matrix}</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>

<span class="sd">        prevalence_index</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">_div</span><span class="p">(</span><span class="nb">abs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">FN</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">FP</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">grand_total</span><span class="p">)</span></div>

<div class="viewcode-block" id="ConfusionMatrix2.informedness"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.ConfusionMatrix2.informedness">[docs]</a>    <span class="k">def</span> <span class="nf">informedness</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Informedness (recall corrected for chance)</span>

<span class="sd">        A complement to markedness. Can be thought of as recall corrected for</span>
<span class="sd">        chance. Alternative formulations:</span>

<span class="sd">        .. math::</span>

<span class="sd">            Informedness &amp;= Sensitivity + Specificity - 1.0 \\\\</span>
<span class="sd">                         &amp;= TPR - FPR</span>

<span class="sd">        In the case of ranked predictions, TPR can be plotted on the y-axis</span>
<span class="sd">        with FPR on the x-axis. The resulting plot is known as Receiver</span>
<span class="sd">        Operating Characteristic (ROC) curve [1]_. The delta between a point on</span>
<span class="sd">        the ROC curve and the diagonal is equal to the value of informedness at</span>
<span class="sd">        the given FPR threshold.</span>

<span class="sd">        This measure was first proposed for evaluating medical diagnostics</span>
<span class="sd">        tests in [2]_, and was also used in meteorology under the name &quot;True</span>
<span class="sd">        Skill Score&quot; [3]_.</span>

<span class="sd">        Synonyms: Youden&#39;s J, True Skill Score, Hannssen-Kuiper Score,</span>
<span class="sd">        Attributable Risk, DeltaP.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>

<span class="sd">        markedness</span>

<span class="sd">        References</span>
<span class="sd">        ----------</span>

<span class="sd">        .. [1] `Fawcett, T. (2006). An introduction to ROC analysis. Pattern</span>
<span class="sd">               recognition letters, 27(8), 861-874.</span>
<span class="sd">               &lt;http://doi.org/10.1016/j.patrec.2005.10.010&gt;`_</span>

<span class="sd">        .. [2] `Youden, W. J. (1950). Index for rating diagnostic tests. Cancer,</span>
<span class="sd">               3(1), 32-35.</span>
<span class="sd">               &lt;http://www.ncbi.nlm.nih.gov/pubmed/15405679&gt;`_</span>

<span class="sd">        .. [3] `Doswell III, C. A., Davies-Jones, R., &amp; Keller, D. L. (1990). On</span>
<span class="sd">               summary measures of skill in rare event forecasting based on</span>
<span class="sd">               contingency tables. Weather and Forecasting, 5(4), 576-585.</span>
<span class="sd">               &lt;http://journals.ametsoc.org/doi/abs/10.1175/1520-0434%281990%29005%3C0576%3AOSMOSI%3E2.0.CO%3B2&gt;`_</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">a</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_ccw</span><span class="p">()</span>
        <span class="n">p1</span><span class="p">,</span> <span class="n">q1</span> <span class="o">=</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span><span class="p">,</span> <span class="n">c</span> <span class="o">+</span> <span class="n">d</span>
        <span class="n">n</span> <span class="o">=</span> <span class="n">p1</span> <span class="o">+</span> <span class="n">q1</span>

        <span class="k">if</span> <span class="n">n</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
        <span class="k">elif</span> <span class="n">p1</span> <span class="o">==</span> <span class="n">n</span><span class="p">:</span>
            <span class="k">return</span> <span class="mf">0.0</span>
            <span class="c1"># return _div(a - b, 2 * (a + b))</span>
        <span class="k">elif</span> <span class="n">q1</span> <span class="o">==</span> <span class="n">n</span><span class="p">:</span>
            <span class="k">return</span> <span class="mf">0.0</span>
            <span class="c1"># return _div(d - c, 2 * (d + c))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">_div</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">covar</span><span class="p">(),</span> <span class="n">p1</span> <span class="o">*</span> <span class="n">q1</span><span class="p">)</span></div>

<div class="viewcode-block" id="ConfusionMatrix2.markedness"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.ConfusionMatrix2.markedness">[docs]</a>    <span class="k">def</span> <span class="nf">markedness</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Markedness (precision corrected for chance)</span>

<span class="sd">        A complement to informedness. Can be thought of as precision corrected</span>
<span class="sd">        for chance. Alternative formulations:</span>

<span class="sd">        .. math::</span>

<span class="sd">            Markedness &amp;= PPV + NPV - 1.0 \\\\</span>
<span class="sd">                       &amp;= PPV - FOR</span>

<span class="sd">        In the case of ranked predictions, PPV can be plotted on the y-axis</span>
<span class="sd">        with FOR on the x-axis. The resulting plot is known as Relative</span>
<span class="sd">        Operating Level (ROL) curve [1]_. The delta between a point on the ROL</span>
<span class="sd">        curve and the diagonal is equal to the value of markedness at the given</span>
<span class="sd">        FOR threshold.</span>

<span class="sd">        Synonyms: DeltaP</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>

<span class="sd">        informedness</span>

<span class="sd">        References</span>
<span class="sd">        ----------</span>

<span class="sd">        .. [1] `Mason, S. J., &amp; Graham, N. E. (2002). Areas beneath the</span>
<span class="sd">               relative operating characteristics (ROC) and relative</span>
<span class="sd">               operating levels (ROL) curves: Statistical significance</span>
<span class="sd">               and interpretation. Quarterly Journal of the Royal</span>
<span class="sd">               Meteorological Society, 128(584), 2145-2166.</span>
<span class="sd">               &lt;https://doi.org/10.1256/003590002320603584&gt;`_</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">a</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_ccw</span><span class="p">()</span>
        <span class="n">p2</span><span class="p">,</span> <span class="n">q2</span> <span class="o">=</span> <span class="n">a</span> <span class="o">+</span> <span class="n">c</span><span class="p">,</span> <span class="n">b</span> <span class="o">+</span> <span class="n">d</span>
        <span class="n">n</span> <span class="o">=</span> <span class="n">p2</span> <span class="o">+</span> <span class="n">q2</span>

        <span class="k">if</span> <span class="n">n</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
        <span class="k">elif</span> <span class="n">p2</span> <span class="o">==</span> <span class="n">n</span><span class="p">:</span>
            <span class="k">return</span> <span class="mf">0.0</span>
            <span class="c1"># return _div(a - c, 2 * (a + c))</span>
        <span class="k">elif</span> <span class="n">q2</span> <span class="o">==</span> <span class="n">n</span><span class="p">:</span>
            <span class="k">return</span> <span class="mf">0.0</span>
            <span class="c1"># return _div(d - b, 2 * (d + b))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">_div</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">covar</span><span class="p">(),</span> <span class="n">p2</span> <span class="o">*</span> <span class="n">q2</span><span class="p">)</span></div>

<div class="viewcode-block" id="ConfusionMatrix2.xcoeff"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.ConfusionMatrix2.xcoeff">[docs]</a>    <span class="k">def</span> <span class="nf">xcoeff</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Alternative to ``loevinger_coeff`` but with -1 lower bound</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">a</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_ccw</span><span class="p">()</span>
        <span class="n">p1</span><span class="p">,</span> <span class="n">q1</span> <span class="o">=</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span><span class="p">,</span> <span class="n">c</span> <span class="o">+</span> <span class="n">d</span>
        <span class="n">p2</span><span class="p">,</span> <span class="n">q2</span> <span class="o">=</span> <span class="n">a</span> <span class="o">+</span> <span class="n">c</span><span class="p">,</span> <span class="n">b</span> <span class="o">+</span> <span class="n">d</span>
        <span class="n">n</span> <span class="o">=</span> <span class="n">p1</span> <span class="o">+</span> <span class="n">q1</span>

        <span class="n">cov</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">covar</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">n</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
        <span class="k">elif</span> <span class="n">a</span> <span class="o">==</span> <span class="n">n</span> <span class="ow">or</span> <span class="n">d</span> <span class="o">==</span> <span class="n">n</span><span class="p">:</span>
            <span class="k">return</span> <span class="mf">0.5</span>
        <span class="k">elif</span> <span class="n">b</span> <span class="o">==</span> <span class="n">n</span> <span class="ow">or</span> <span class="n">c</span> <span class="o">==</span> <span class="n">n</span><span class="p">:</span>
            <span class="k">return</span> <span class="o">-</span><span class="mf">1.0</span>
        <span class="k">elif</span> <span class="n">cov</span> <span class="o">&gt;</span> <span class="mf">0.0</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">_div</span><span class="p">(</span><span class="n">cov</span><span class="p">,</span> <span class="nb">min</span><span class="p">(</span><span class="n">p1</span> <span class="o">*</span> <span class="n">q2</span><span class="p">,</span> <span class="n">p2</span> <span class="o">*</span> <span class="n">q1</span><span class="p">))</span>
        <span class="k">elif</span> <span class="n">cov</span> <span class="o">&lt;</span> <span class="mf">0.0</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">_div</span><span class="p">(</span><span class="n">cov</span><span class="p">,</span> <span class="nb">min</span><span class="p">(</span><span class="n">n</span> <span class="o">*</span> <span class="n">c</span><span class="p">,</span> <span class="n">n</span> <span class="o">*</span> <span class="n">b</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="mf">0.0</span></div>

<div class="viewcode-block" id="ConfusionMatrix2.pairwise_hcv"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.ConfusionMatrix2.pairwise_hcv">[docs]</a>    <span class="k">def</span> <span class="nf">pairwise_hcv</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Pairwise homogeneity, completeness, and their geometric mean</span>

<span class="sd">        Each of the two one-sided measures is defined as follows:</span>

<span class="sd">        .. math::</span>

<span class="sd">            \\hat{M}_{adj} = \\frac{M - E[M]}{M_{max} - min(E[M], M)}.</span>

<span class="sd">        It is clear from the definition above that *iff* :math:`M &lt; E[M]` and</span>
<span class="sd">        :math:`M \\leq M_{max}`, the denominator will switch from the standard</span>
<span class="sd">        normalization interval to a larger one, thereby ensuring that</span>
<span class="sd">        :math:`-1.0 \\leq \\hat{M}_{adj} \\leq 1.0`.  The definition for the</span>
<span class="sd">        bottom half of the range can also be expressed in terms of the standard</span>
<span class="sd">        adjusted value:</span>

<span class="sd">        .. math::</span>

<span class="sd">            \\hat{M}_{adj} = \\frac{M_{adj}}{(1 + |M_{adj}|^n)^{1/n}}, \\quad M_{adj} &lt; 0, n = 1.</span>

<span class="sd">        The resulting measure is not symmetric over its range (negative values</span>
<span class="sd">        are scaled differently from positive values), however this should not</span>
<span class="sd">        matter for applications where negative correlation does not carry any</span>
<span class="sd">        special meaning other than being additional evidence for absence of</span>
<span class="sd">        positive correlation.  Such as a situation occurs in pairwise confusion</span>
<span class="sd">        matrices used in cluster analysis. Nevertheless, if more symmetric</span>
<span class="sd">        behavior near zero is desired, the upper part of the negative range can</span>
<span class="sd">        be linearized either by increasing :math:`n` in the definition above or</span>
<span class="sd">        by replacing it with :math:`\\hat{M}_{adj} = tanh(M_{adj})` transform.</span>

<span class="sd">        For the compound measure, the geometric mean was chosen over the</span>
<span class="sd">        harmonic after the results of a Monte Carlo power analysis, due to</span>
<span class="sd">        slightly better discriminating performance. For positive matrices, the</span>
<span class="sd">        geometric mean is equal to ``matthews_corr``, while the harmonic mean</span>
<span class="sd">        would have been equal to ``kappa``. For negative matrices, the harmonic</span>
<span class="sd">        mean would have remained monotonic (though not equal) to Kappa, while</span>
<span class="sd">        the geometric mean is neither monotonic nor equal to MCC, despite the</span>
<span class="sd">        two being closely correlated. The discriminating performance indices of</span>
<span class="sd">        the geometric mean and of MCC are empirically the same (equal to within</span>
<span class="sd">        rounding error).</span>

<span class="sd">        For matrices with negative covariance, it is possible to switch to</span>
<span class="sd">        ``markedness`` and ``informedness`` as one-sided components</span>
<span class="sd">        (homogeneity and completeness, respectively). However, the desirable</span>
<span class="sd">        property of measure orthogonality will not be preserved then, since</span>
<span class="sd">        markedness and informedness exhibit strong correlation under the</span>
<span class="sd">        assumed null model.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">a</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_ccw</span><span class="p">()</span>
        <span class="n">p1</span><span class="p">,</span> <span class="n">q1</span> <span class="o">=</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span><span class="p">,</span> <span class="n">c</span> <span class="o">+</span> <span class="n">d</span>
        <span class="n">p2</span><span class="p">,</span> <span class="n">q2</span> <span class="o">=</span> <span class="n">a</span> <span class="o">+</span> <span class="n">c</span><span class="p">,</span> <span class="n">b</span> <span class="o">+</span> <span class="n">d</span>
        <span class="n">n</span> <span class="o">=</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span> <span class="o">+</span> <span class="n">c</span> <span class="o">+</span> <span class="n">d</span>

        <span class="n">cov</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">covar</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">n</span> <span class="o">==</span> <span class="mf">0.0</span><span class="p">:</span>
            <span class="n">k0</span><span class="p">,</span> <span class="n">k1</span><span class="p">,</span> <span class="n">k2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
        <span class="k">elif</span> <span class="n">a</span> <span class="o">==</span> <span class="n">n</span> <span class="ow">or</span> <span class="n">d</span> <span class="o">==</span> <span class="n">n</span><span class="p">:</span>
            <span class="n">k0</span><span class="p">,</span> <span class="n">k1</span><span class="p">,</span> <span class="n">k2</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span>
        <span class="k">elif</span> <span class="n">b</span> <span class="o">==</span> <span class="n">n</span><span class="p">:</span>
            <span class="n">k0</span><span class="p">,</span> <span class="n">k1</span><span class="p">,</span> <span class="n">k2</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0</span>
        <span class="k">elif</span> <span class="n">c</span> <span class="o">==</span> <span class="n">n</span><span class="p">:</span>
            <span class="n">k0</span><span class="p">,</span> <span class="n">k1</span><span class="p">,</span> <span class="n">k2</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0</span>
        <span class="k">elif</span> <span class="n">p1</span> <span class="o">==</span> <span class="n">n</span> <span class="ow">or</span> <span class="n">q2</span> <span class="o">==</span> <span class="n">n</span><span class="p">:</span>
            <span class="n">k0</span><span class="p">,</span> <span class="n">k1</span><span class="p">,</span> <span class="n">k2</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span>
        <span class="k">elif</span> <span class="n">p2</span> <span class="o">==</span> <span class="n">n</span> <span class="ow">or</span> <span class="n">q1</span> <span class="o">==</span> <span class="n">n</span><span class="p">:</span>
            <span class="n">k0</span><span class="p">,</span> <span class="n">k1</span><span class="p">,</span> <span class="n">k2</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span>
        <span class="k">elif</span> <span class="n">cov</span> <span class="o">&gt;</span> <span class="mf">0.0</span><span class="p">:</span>
            <span class="n">k0</span> <span class="o">=</span> <span class="n">_div</span><span class="p">(</span><span class="n">cov</span><span class="p">,</span> <span class="n">p2</span> <span class="o">*</span> <span class="n">q1</span><span class="p">)</span>
            <span class="n">k1</span> <span class="o">=</span> <span class="n">_div</span><span class="p">(</span><span class="n">cov</span><span class="p">,</span> <span class="n">p1</span> <span class="o">*</span> <span class="n">q2</span><span class="p">)</span>
            <span class="n">k2</span> <span class="o">=</span> <span class="n">_div</span><span class="p">(</span><span class="n">cov</span><span class="p">,</span> <span class="n">sqrt</span><span class="p">(</span><span class="n">p1</span> <span class="o">*</span> <span class="n">q1</span> <span class="o">*</span> <span class="n">p2</span> <span class="o">*</span> <span class="n">q2</span><span class="p">))</span>
        <span class="k">elif</span> <span class="n">cov</span> <span class="o">&lt;</span> <span class="mf">0.0</span><span class="p">:</span>
            <span class="n">k0</span> <span class="o">=</span> <span class="n">_div</span><span class="p">(</span><span class="n">cov</span><span class="p">,</span> <span class="n">n</span> <span class="o">*</span> <span class="n">c</span><span class="p">)</span>
            <span class="n">k1</span> <span class="o">=</span> <span class="n">_div</span><span class="p">(</span><span class="n">cov</span><span class="p">,</span> <span class="n">n</span> <span class="o">*</span> <span class="n">b</span><span class="p">)</span>
            <span class="n">k2</span> <span class="o">=</span> <span class="n">_div</span><span class="p">(</span><span class="n">cov</span><span class="p">,</span> <span class="n">n</span> <span class="o">*</span> <span class="n">sqrt</span><span class="p">(</span><span class="n">b</span> <span class="o">*</span> <span class="n">c</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">k0</span><span class="p">,</span> <span class="n">k1</span><span class="p">,</span> <span class="n">k2</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span>

        <span class="k">return</span> <span class="n">k0</span><span class="p">,</span> <span class="n">k1</span><span class="p">,</span> <span class="n">k2</span></div>

<div class="viewcode-block" id="ConfusionMatrix2.kappas"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.ConfusionMatrix2.kappas">[docs]</a>    <span class="k">def</span> <span class="nf">kappas</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Pairwise precision and recall corrected for chance</span>

<span class="sd">        Kappa decomposes into a pair of components (regression coefficients),</span>
<span class="sd">        :math:`\\kappa_0` (precision-like) and :math:`\\kappa_1` (recall-like),</span>
<span class="sd">        of which it is a harmonic mean:</span>

<span class="sd">        .. math::</span>

<span class="sd">            \\kappa_0 = \\frac{cov}{p_2 q_1}, \\quad \\kappa_1 = \\frac{cov}{p_1 q_2}.</span>

<span class="sd">        These coefficients are interesting because they represent precision and</span>
<span class="sd">        recall, respectively, corrected for chance by subtracting the</span>
<span class="sd">        fixed-margin null model. In clustering context, :math:`\\kappa_0`</span>
<span class="sd">        corresponds to pairwise homogeneity, while :math:`\\kappa_1`</span>
<span class="sd">        corresponds to pairwise completeness. The geometric mean of the two</span>
<span class="sd">        components is equal to Matthews&#39; Correlation Coefficient, while their</span>
<span class="sd">        maximum is equal to Loevinger&#39;s H when :math:`ad \\geq bc`.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>

<span class="sd">        kappa, loevinger_coeff, matthews_corr</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">a</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_ccw</span><span class="p">()</span>
        <span class="n">p1</span><span class="p">,</span> <span class="n">q1</span> <span class="o">=</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span><span class="p">,</span> <span class="n">c</span> <span class="o">+</span> <span class="n">d</span>
        <span class="n">p2</span><span class="p">,</span> <span class="n">q2</span> <span class="o">=</span> <span class="n">a</span> <span class="o">+</span> <span class="n">c</span><span class="p">,</span> <span class="n">b</span> <span class="o">+</span> <span class="n">d</span>
        <span class="n">n</span> <span class="o">=</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span> <span class="o">+</span> <span class="n">c</span> <span class="o">+</span> <span class="n">d</span>

        <span class="k">if</span> <span class="n">a</span> <span class="o">==</span> <span class="n">n</span> <span class="ow">or</span> <span class="n">d</span> <span class="o">==</span> <span class="n">n</span><span class="p">:</span>
            <span class="n">k0</span><span class="p">,</span> <span class="n">k1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
        <span class="k">elif</span> <span class="n">b</span> <span class="o">==</span> <span class="n">n</span><span class="p">:</span>
            <span class="n">k0</span><span class="p">,</span> <span class="n">k1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">NINF</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0</span>
        <span class="k">elif</span> <span class="n">c</span> <span class="o">==</span> <span class="n">n</span><span class="p">:</span>
            <span class="n">k0</span><span class="p">,</span> <span class="n">k1</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">NINF</span>
        <span class="k">elif</span> <span class="n">p1</span> <span class="o">==</span> <span class="n">n</span> <span class="ow">or</span> <span class="n">q2</span> <span class="o">==</span> <span class="n">n</span><span class="p">:</span>
            <span class="n">k0</span><span class="p">,</span> <span class="n">k1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="mf">0.0</span>
        <span class="k">elif</span> <span class="n">p2</span> <span class="o">==</span> <span class="n">n</span> <span class="ow">or</span> <span class="n">q1</span> <span class="o">==</span> <span class="n">n</span><span class="p">:</span>
            <span class="n">k0</span><span class="p">,</span> <span class="n">k1</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">cov</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">covar</span><span class="p">()</span>
            <span class="n">p2_q1</span><span class="p">,</span> <span class="n">p1_q2</span> <span class="o">=</span> <span class="n">p2</span> <span class="o">*</span> <span class="n">q1</span><span class="p">,</span> <span class="n">p1</span> <span class="o">*</span> <span class="n">q2</span>
            <span class="n">k0</span><span class="p">,</span> <span class="n">k1</span> <span class="o">=</span> <span class="n">_div</span><span class="p">(</span><span class="n">cov</span><span class="p">,</span> <span class="n">p2_q1</span><span class="p">),</span> <span class="n">_div</span><span class="p">(</span><span class="n">cov</span><span class="p">,</span> <span class="n">p1_q2</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">k0</span><span class="p">,</span> <span class="n">k1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">kappa</span><span class="p">()</span></div>

<div class="viewcode-block" id="ConfusionMatrix2.loevinger_coeff"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.ConfusionMatrix2.loevinger_coeff">[docs]</a>    <span class="k">def</span> <span class="nf">loevinger_coeff</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Loevinger&#39;s Index of Homogeneity (Loevinger&#39;s H)</span>

<span class="sd">        Given a clustering (numbers correspond to class labels, inner groups to</span>
<span class="sd">        clusters) with perfect homogeneity but imperfect completeness, Loevinger</span>
<span class="sd">        coefficient returns a perfect score on the corresponding pairwise</span>
<span class="sd">        co-association matrix::</span>

<span class="sd">            &gt;&gt;&gt; clusters = [[0, 0], [0, 0, 0, 0], [1, 1, 1, 1]]</span>
<span class="sd">            &gt;&gt;&gt; t = ClusteringMetrics.from_clusters(clusters)</span>
<span class="sd">            &gt;&gt;&gt; t.pairwise.loevinger_coeff()</span>
<span class="sd">            1.0</span>

<span class="sd">        At the same time, kappa and Matthews coefficients are 0.63 and 0.68,</span>
<span class="sd">        respectively. Loevinger coefficient will also return a perfect score</span>
<span class="sd">        for the dual situation::</span>

<span class="sd">            &gt;&gt;&gt; clusters = [[0, 2, 2, 0, 0, 0], [1, 1, 1, 1]]</span>
<span class="sd">            &gt;&gt;&gt; t = ClusteringMetrics.from_clusters(clusters)</span>
<span class="sd">            &gt;&gt;&gt; t.pairwise.loevinger_coeff()</span>
<span class="sd">            1.0</span>

<span class="sd">        Loevinger&#39;s coefficient has a unique property: all two-way correlation</span>
<span class="sd">        coefficients on a 2x2 table that are in L-family (including Kappa and</span>
<span class="sd">        Matthews&#39; correlation coefficient) become Loevinger&#39;s coefficient after</span>
<span class="sd">        normalization by maximum value [1]_. However, this measure is not</span>
<span class="sd">        symmetric: when :math:`ad &lt; bc`, it does not have a lower bound. For an</span>
<span class="sd">        equivalent symmetric measure, use Cole coefficient.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        cole_coeff</span>

<span class="sd">        References</span>
<span class="sd">        ----------</span>

<span class="sd">        .. [1] `Warrens, M. J. (2008). On association coefficients for 2x2</span>
<span class="sd">               tables and properties that do not depend on the marginal</span>
<span class="sd">               distributions.  Psychometrika, 73(4), 777-789.</span>
<span class="sd">               &lt;https://doi.org/10.1007/s11336-008-9070-3&gt;`_</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">a</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_ccw</span><span class="p">()</span>
        <span class="n">p1</span><span class="p">,</span> <span class="n">q1</span> <span class="o">=</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span><span class="p">,</span> <span class="n">c</span> <span class="o">+</span> <span class="n">d</span>
        <span class="n">p2</span><span class="p">,</span> <span class="n">q2</span> <span class="o">=</span> <span class="n">a</span> <span class="o">+</span> <span class="n">c</span><span class="p">,</span> <span class="n">b</span> <span class="o">+</span> <span class="n">d</span>
        <span class="n">n</span> <span class="o">=</span> <span class="n">p1</span> <span class="o">+</span> <span class="n">q1</span>

        <span class="n">cov</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">covar</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">n</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
        <span class="k">elif</span> <span class="n">a</span> <span class="o">==</span> <span class="n">n</span> <span class="ow">or</span> <span class="n">d</span> <span class="o">==</span> <span class="n">n</span><span class="p">:</span>
            <span class="c1"># only one (diagonal) cell is non-zero</span>
            <span class="k">return</span> <span class="mf">0.5</span>
        <span class="k">elif</span> <span class="n">cov</span> <span class="o">==</span> <span class="mf">0.0</span><span class="p">:</span>
            <span class="k">return</span> <span class="mf">0.0</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">_div</span><span class="p">(</span><span class="n">cov</span><span class="p">,</span> <span class="nb">min</span><span class="p">(</span><span class="n">p1</span> <span class="o">*</span> <span class="n">q2</span><span class="p">,</span> <span class="n">p2</span> <span class="o">*</span> <span class="n">q1</span><span class="p">))</span></div>

<div class="viewcode-block" id="ConfusionMatrix2.kappa"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.ConfusionMatrix2.kappa">[docs]</a>    <span class="k">def</span> <span class="nf">kappa</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Cohen&#39;s Kappa (Interrater Agreement)</span>

<span class="sd">        Kappa coefficient is best known in the psychology field where it was</span>
<span class="sd">        introduced to measure interrater agreement [1]_. It has also been used</span>
<span class="sd">        in replication studies [2]_, clustering evaluation [3]_, image</span>
<span class="sd">        segmentation [4]_, feature selection [5]_ [6]_, forecasting [7]_, and</span>
<span class="sd">        network link prediction [8]_. The first derivation of this measure is</span>
<span class="sd">        in [9]_.</span>

<span class="sd">        Kappa can be derived by correcting either Accuracy (Simple Matching</span>
<span class="sd">        Coefficient, Rand Index) or F1-score (Dice Coefficient) for chance.</span>
<span class="sd">        Conversely, Dice coefficient can be derived from Kappa by obtaining its</span>
<span class="sd">        limit as :math:`d \\rightarrow \\infty`. Normalizing Kappa by its</span>
<span class="sd">        maximum value given fixed-margin table gives Loevinger&#39;s H.</span>

<span class="sd">        Synonyms: Adjusted Rand Index, Heidke Skill Score</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        kappas, loevinger_coeff, matthews_corr, dice_coeff</span>

<span class="sd">        References</span>
<span class="sd">        ----------</span>

<span class="sd">        .. [1] `Cohen, J. (1960). A coefficient of agreement for nominal scales.</span>
<span class="sd">               Educational and psychological measurement, 20(1), 37-46.</span>
<span class="sd">               &lt;https://doi.org/10.1177/001316446002000104&gt;`_</span>

<span class="sd">        .. [2] `Arabie, P., Hubert, L. J., &amp; De Soete, G. (1996). Clustering</span>
<span class="sd">               validation: results and implications for applied analyses (p.</span>
<span class="sd">               341).  World Scientific Pub Co Inc.</span>
<span class="sd">               &lt;https://doi.org/10.1142/9789812832153_0010&gt;`_</span>

<span class="sd">        .. [3] `Warrens, M. J. (2008). On the equivalence of Cohen&#39;s kappa and</span>
<span class="sd">               the Hubert-Arabie adjusted Rand index. Journal of Classification,</span>
<span class="sd">               25(2), 177-183.</span>
<span class="sd">               &lt;https://doi.org/10.1007/s00357-008-9023-7&gt;`_</span>

<span class="sd">        .. [4] `Briggman, K., Denk, W., Seung, S., Helmstaedter, M. N., &amp;</span>
<span class="sd">               Turaga, S. C. (2009). Maximin affinity learning of image</span>
<span class="sd">               segmentation. In Advances in Neural Information Processing</span>
<span class="sd">               Systems (pp. 1865-1873).</span>
<span class="sd">               &lt;http://books.nips.cc/papers/files/nips22/NIPS2009_0084.pdf&gt;`_</span>

<span class="sd">        .. [5] `Santos, J. M., &amp; Embrechts, M. (2009). On the use of the</span>
<span class="sd">               adjusted rand index as a metric for evaluating supervised</span>
<span class="sd">               classification. In Artificial neural networks - ICANN 2009 (pp.</span>
<span class="sd">               175-184).  Springer Berlin Heidelberg.</span>
<span class="sd">               &lt;https://doi.org/10.1007/978-3-642-04277-5_18&gt;`_</span>

<span class="sd">        .. [6] `Santos, J. M., &amp; Ramos, S. (2010, November). Using a clustering</span>
<span class="sd">               similarity measure for feature selection in high dimensional</span>
<span class="sd">               data sets.  In Intelligent Systems Design and Applications</span>
<span class="sd">               (ISDA), 2010 10th International Conference on (pp. 900-905).</span>
<span class="sd">               IEEE.</span>
<span class="sd">               &lt;http://dx.doi.org/10.1109/ISDA.2010.5687073&gt;`_</span>

<span class="sd">        .. [7] `Doswell III, C. A., Davies-Jones, R., &amp; Keller, D. L. (1990). On</span>
<span class="sd">               summary measures of skill in rare event forecasting based on</span>
<span class="sd">               contingency tables. Weather and Forecasting, 5(4), 576-585.</span>
<span class="sd">               &lt;http://journals.ametsoc.org/doi/abs/10.1175/1520-0434%281990%29005%3C0576%3AOSMOSI%3E2.0.CO%3B2&gt;`_</span>

<span class="sd">        .. [8] `Hoffman, M., Steinley, D., &amp; Brusco, M. J. (2015). A note on</span>
<span class="sd">               using the adjusted Rand index for link prediction in networks.</span>
<span class="sd">               Social Networks, 42, 72-79.</span>
<span class="sd">               &lt;http://dx.doi.org/10.1016/j.socnet.2015.03.002&gt;`_</span>

<span class="sd">        .. [9] `Heidke, Paul. &quot;Berechnung des Erfolges und der Gute der</span>
<span class="sd">               Windstarkevorhersagen im Sturmwarnungsdienst.&quot; Geografiska</span>
<span class="sd">               Annaler (1926): 301-349.</span>
<span class="sd">               &lt;http://www.jstor.org/stable/519729&gt;`_</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">a</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_ccw</span><span class="p">()</span>
        <span class="n">p1</span><span class="p">,</span> <span class="n">q1</span> <span class="o">=</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span><span class="p">,</span> <span class="n">c</span> <span class="o">+</span> <span class="n">d</span>
        <span class="n">p2</span><span class="p">,</span> <span class="n">q2</span> <span class="o">=</span> <span class="n">a</span> <span class="o">+</span> <span class="n">c</span><span class="p">,</span> <span class="n">b</span> <span class="o">+</span> <span class="n">d</span>
        <span class="n">n</span> <span class="o">=</span> <span class="n">p1</span> <span class="o">+</span> <span class="n">q1</span>

        <span class="k">if</span> <span class="n">n</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
        <span class="k">elif</span> <span class="n">a</span> <span class="o">==</span> <span class="n">n</span> <span class="ow">or</span> <span class="n">d</span> <span class="o">==</span> <span class="n">n</span><span class="p">:</span>
            <span class="c1"># only one (diagonal) cell is non-zero</span>
            <span class="k">return</span> <span class="mf">0.5</span>

        <span class="k">return</span> <span class="n">_div</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">covar</span><span class="p">(),</span> <span class="n">p1</span> <span class="o">*</span> <span class="n">q2</span> <span class="o">+</span> <span class="n">p2</span> <span class="o">*</span> <span class="n">q1</span><span class="p">)</span></div>

<div class="viewcode-block" id="ConfusionMatrix2.mp_corr"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.ConfusionMatrix2.mp_corr">[docs]</a>    <span class="k">def</span> <span class="nf">mp_corr</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Maxwell &amp; Pilliner&#39;s association index</span>

<span class="sd">        Another covariance-based association index corrected for chance. Like</span>
<span class="sd">        MCC, based on a mean of informedness and markedness, except uses a</span>
<span class="sd">        harmonic mean instead of geometric. Like Kappa, turns into Dice</span>
<span class="sd">        coefficient (F-score) as &#39;d&#39; approaches infinity.</span>

<span class="sd">        On typical problems, the resolving power of this coefficient is nearly</span>
<span class="sd">        identical to that of Cohen&#39;s Kappa and is only very slightly below that</span>
<span class="sd">        of Matthews&#39; correlation coefficient.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        kappa, matthews_corr</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">a</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_ccw</span><span class="p">()</span>
        <span class="n">p1</span><span class="p">,</span> <span class="n">q1</span> <span class="o">=</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span><span class="p">,</span> <span class="n">c</span> <span class="o">+</span> <span class="n">d</span>
        <span class="n">p2</span><span class="p">,</span> <span class="n">q2</span> <span class="o">=</span> <span class="n">a</span> <span class="o">+</span> <span class="n">c</span><span class="p">,</span> <span class="n">b</span> <span class="o">+</span> <span class="n">d</span>
        <span class="n">n</span> <span class="o">=</span> <span class="n">p1</span> <span class="o">+</span> <span class="n">q1</span>

        <span class="k">if</span> <span class="n">n</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
        <span class="k">elif</span> <span class="n">a</span> <span class="o">==</span> <span class="n">n</span> <span class="ow">or</span> <span class="n">d</span> <span class="o">==</span> <span class="n">n</span><span class="p">:</span>
            <span class="c1"># only one (diagonal) cell is non-zero</span>
            <span class="k">return</span> <span class="mf">0.5</span>
        <span class="k">elif</span> <span class="n">b</span> <span class="o">==</span> <span class="n">n</span> <span class="ow">or</span> <span class="n">c</span> <span class="o">==</span> <span class="n">n</span><span class="p">:</span>
            <span class="c1"># only one (non-diagonal) cell is non-zero</span>
            <span class="k">return</span> <span class="o">-</span><span class="mf">0.5</span>

        <span class="k">return</span> <span class="n">_div</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">covar</span><span class="p">(),</span> <span class="n">p1</span> <span class="o">*</span> <span class="n">q1</span> <span class="o">+</span> <span class="n">p2</span> <span class="o">*</span> <span class="n">q2</span><span class="p">)</span></div>

<div class="viewcode-block" id="ConfusionMatrix2.matthews_corr"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.ConfusionMatrix2.matthews_corr">[docs]</a>    <span class="k">def</span> <span class="nf">matthews_corr</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Matthews Correlation Coefficient (Phi coefficient)</span>

<span class="sd">        MCC is directly related to the Chi-square statistic. Its value is equal</span>
<span class="sd">        to the Chi-square value normalized by the maximum value the Chi-square</span>
<span class="sd">        can achieve with given margins (for a 2x2 table, the maximum Chi-square</span>
<span class="sd">        score is equal to the grand total N) transformed to correlation space</span>
<span class="sd">        by taking a square root.</span>

<span class="sd">        MCC is a also a geometric mean of informedness and markedness (the</span>
<span class="sd">        regression coefficients of the problem and its dual). As :math:`d</span>
<span class="sd">        \\rightarrow \\infty`, MCC turns into Ochiai coefficient. Unlike with</span>
<span class="sd">        Kappa, normalizing the corresponding similarity coefficient for chance</span>
<span class="sd">        by subtracting the fixed-margin null model does not produce MCC in</span>
<span class="sd">        return, but gives a different index with equivalent discriminating</span>
<span class="sd">        power to that of MCC. Normalizing MCC by its maximum value under fixed-</span>
<span class="sd">        margin model gives Loevinger&#39;s H.</span>

<span class="sd">        Empirically, the discriminating power of MCC is sligtly better than</span>
<span class="sd">        that of ``mp_corr`` and ``kappa``, and is only lower than that of</span>
<span class="sd">        ``loevinger_coeff`` under highly biased conditions. While MCC is a</span>
<span class="sd">        commonly used and recently preferred measure of prediction and</span>
<span class="sd">        reproducibility [1]_, it is somewhat strange that one can hardly find</span>
<span class="sd">        any literature that uses this index in clustering comparison context,</span>
<span class="sd">        with some rare exceptions [2]_ [3]_.</span>

<span class="sd">        Synonyms: Phi Coefficient, Product-Moment Correlation</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        kappa, mp_corr, ochiai_coeff</span>

<span class="sd">        References</span>
<span class="sd">        ----------</span>

<span class="sd">        .. [1] `MAQC Consortium. (2010). The MicroArray Quality Control</span>
<span class="sd">               (MAQC)-II study of common practices for the development and</span>
<span class="sd">               validation of microarray-based predictive models. Nature</span>
<span class="sd">               biotechnology, 28(8), 827-838.</span>
<span class="sd">               &lt;http://doi.org/10.1038/nbt.1665&gt;`_</span>

<span class="sd">        .. [2] `Xiao, J., Wang, X. F., Yang, Z. F., &amp; Xu, C. W. (2008).</span>
<span class="sd">               Comparison of Supervised Clustering Methods for the Analysis of</span>
<span class="sd">               DNA Microarray Expression Data. Agricultural Sciences in China,</span>
<span class="sd">               7(2), 129-139.</span>
<span class="sd">               &lt;http://dx.doi.org/10.1016/S1671-2927%2808%2960032-2&gt;`_</span>

<span class="sd">        .. [3] `Kao, D. (2012). Using Matthews correlation coefficient to</span>
<span class="sd">               cluster annotations.  NextGenetics (personal blog).</span>
<span class="sd">               &lt;http://blog.nextgenetics.net/?e=47&gt;`_</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">a</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_ccw</span><span class="p">()</span>
        <span class="n">p1</span><span class="p">,</span> <span class="n">q1</span> <span class="o">=</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span><span class="p">,</span> <span class="n">c</span> <span class="o">+</span> <span class="n">d</span>
        <span class="n">p2</span><span class="p">,</span> <span class="n">q2</span> <span class="o">=</span> <span class="n">a</span> <span class="o">+</span> <span class="n">c</span><span class="p">,</span> <span class="n">b</span> <span class="o">+</span> <span class="n">d</span>
        <span class="n">n</span> <span class="o">=</span> <span class="n">p1</span> <span class="o">+</span> <span class="n">q1</span>

        <span class="k">if</span> <span class="n">n</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
        <span class="k">elif</span> <span class="n">a</span> <span class="o">==</span> <span class="n">n</span> <span class="ow">or</span> <span class="n">d</span> <span class="o">==</span> <span class="n">n</span><span class="p">:</span>
            <span class="c1"># only one (diagonal) cell is non-zero</span>
            <span class="k">return</span> <span class="mf">0.5</span>
        <span class="k">elif</span> <span class="n">b</span> <span class="o">==</span> <span class="n">n</span> <span class="ow">or</span> <span class="n">c</span> <span class="o">==</span> <span class="n">n</span><span class="p">:</span>
            <span class="c1"># only one (non-diagonal) cell is non-zero</span>
            <span class="k">return</span> <span class="o">-</span><span class="mf">0.5</span>
        <span class="k">elif</span> <span class="n">p1</span> <span class="o">==</span> <span class="n">n</span> <span class="ow">or</span> <span class="n">p2</span> <span class="o">==</span> <span class="n">n</span> <span class="ow">or</span> <span class="n">q1</span> <span class="o">==</span> <span class="n">n</span> <span class="ow">or</span> <span class="n">q2</span> <span class="o">==</span> <span class="n">n</span><span class="p">:</span>
            <span class="c1"># one row or column is zero, another non-zero</span>
            <span class="k">return</span> <span class="mf">0.0</span>

        <span class="k">return</span> <span class="n">_div</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">covar</span><span class="p">(),</span> <span class="n">sqrt</span><span class="p">(</span><span class="n">p1</span> <span class="o">*</span> <span class="n">q1</span> <span class="o">*</span> <span class="n">p2</span> <span class="o">*</span> <span class="n">q2</span><span class="p">))</span></div>

<div class="viewcode-block" id="ConfusionMatrix2.mic_scores"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.ConfusionMatrix2.mic_scores">[docs]</a>    <span class="k">def</span> <span class="nf">mic_scores</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="s1">&#39;harmonic&#39;</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Mutual information-based correlation</span>

<span class="sd">        The coefficient decomposes into regression coefficients defined</span>
<span class="sd">        according to fixed-margin tables. The ``mic1`` coefficient, for</span>
<span class="sd">        example, is obtained by dividing the G-score by the maximum achievable</span>
<span class="sd">        value on a table with fixed true class counts (which here correspond to</span>
<span class="sd">        row totals).  The ``mic0`` is its dual, defined by dividing the G-score</span>
<span class="sd">        by its maximum achievable value with fixed predicted label counts (here</span>
<span class="sd">        represented as column totals).</span>

<span class="sd">        ``mic0`` roughly corresponds to precision (homogeneity) while ``mic1``</span>
<span class="sd">        roughly corresponds to recall (completeness).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">h</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">rsquare</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">entropy_scores</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="n">mean</span><span class="p">)</span>
        <span class="n">covsign</span> <span class="o">=</span> <span class="n">copysign</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">covar</span><span class="p">())</span>
        <span class="n">mic0</span> <span class="o">=</span> <span class="n">covsign</span> <span class="o">*</span> <span class="n">sqrt</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>
        <span class="n">mic1</span> <span class="o">=</span> <span class="n">covsign</span> <span class="o">*</span> <span class="n">sqrt</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>
        <span class="n">mic2</span> <span class="o">=</span> <span class="n">covsign</span> <span class="o">*</span> <span class="n">sqrt</span><span class="p">(</span><span class="n">rsquare</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">mic0</span><span class="p">,</span> <span class="n">mic1</span><span class="p">,</span> <span class="n">mic2</span></div>

<div class="viewcode-block" id="ConfusionMatrix2.yule_q"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.ConfusionMatrix2.yule_q">[docs]</a>    <span class="k">def</span> <span class="nf">yule_q</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Yule&#39;s Q (association index)</span>

<span class="sd">        Yule&#39;s Q relates to the odds ratio (DOR) as follows:</span>

<span class="sd">        .. math::</span>

<span class="sd">            Q = \\frac{DOR - 1}{DOR + 1}.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">a</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_ccw</span><span class="p">()</span>
        <span class="n">p1</span><span class="p">,</span> <span class="n">q1</span> <span class="o">=</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span><span class="p">,</span> <span class="n">c</span> <span class="o">+</span> <span class="n">d</span>
        <span class="n">p2</span><span class="p">,</span> <span class="n">q2</span> <span class="o">=</span> <span class="n">a</span> <span class="o">+</span> <span class="n">c</span><span class="p">,</span> <span class="n">b</span> <span class="o">+</span> <span class="n">d</span>
        <span class="n">n</span> <span class="o">=</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span> <span class="o">+</span> <span class="n">c</span> <span class="o">+</span> <span class="n">d</span>

        <span class="k">if</span> <span class="n">n</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
        <span class="k">elif</span> <span class="n">p1</span> <span class="o">==</span> <span class="n">n</span><span class="p">:</span>
            <span class="c1"># c and d are zero</span>
            <span class="k">return</span> <span class="n">_div</span><span class="p">(</span><span class="n">a</span> <span class="o">-</span> <span class="n">b</span><span class="p">,</span> <span class="n">p1</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">p2</span> <span class="o">==</span> <span class="n">n</span><span class="p">:</span>
            <span class="c1"># b and d are zero</span>
            <span class="k">return</span> <span class="n">_div</span><span class="p">(</span><span class="n">a</span> <span class="o">-</span> <span class="n">c</span><span class="p">,</span> <span class="n">p2</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">q1</span> <span class="o">==</span> <span class="n">n</span><span class="p">:</span>
            <span class="c1"># a and b are zero</span>
            <span class="k">return</span> <span class="n">_div</span><span class="p">(</span><span class="n">d</span> <span class="o">-</span> <span class="n">c</span><span class="p">,</span> <span class="n">q1</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">q2</span> <span class="o">==</span> <span class="n">n</span><span class="p">:</span>
            <span class="c1"># a and c are zero</span>
            <span class="k">return</span> <span class="n">_div</span><span class="p">(</span><span class="n">d</span> <span class="o">-</span> <span class="n">b</span><span class="p">,</span> <span class="n">q2</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">_div</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">covar</span><span class="p">(),</span> <span class="n">a</span> <span class="o">*</span> <span class="n">d</span> <span class="o">+</span> <span class="n">b</span> <span class="o">*</span> <span class="n">c</span><span class="p">)</span></div>

<div class="viewcode-block" id="ConfusionMatrix2.yule_y"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.ConfusionMatrix2.yule_y">[docs]</a>    <span class="k">def</span> <span class="nf">yule_y</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Yule&#39;s Y (colligation coefficient)</span>

<span class="sd">        The Y coefficient was used as basis of a new association</span>
<span class="sd">        measure by accounting for entropy in [1]_.</span>

<span class="sd">        References</span>
<span class="sd">        ----------</span>

<span class="sd">        .. [1] `Hasenclever, D., &amp; Scholz, M. (2013). Comparing measures of</span>
<span class="sd">                association in 2x2 probability tables. arXiv preprint</span>
<span class="sd">                arXiv:1302.6161.</span>
<span class="sd">                &lt;http://arxiv.org/pdf/1302.6161v1.pdf&gt;`_</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">a</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_ccw</span><span class="p">()</span>
        <span class="n">p1</span><span class="p">,</span> <span class="n">q1</span> <span class="o">=</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span><span class="p">,</span> <span class="n">c</span> <span class="o">+</span> <span class="n">d</span>
        <span class="n">p2</span><span class="p">,</span> <span class="n">q2</span> <span class="o">=</span> <span class="n">a</span> <span class="o">+</span> <span class="n">c</span><span class="p">,</span> <span class="n">b</span> <span class="o">+</span> <span class="n">d</span>
        <span class="n">n</span> <span class="o">=</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span> <span class="o">+</span> <span class="n">c</span> <span class="o">+</span> <span class="n">d</span>

        <span class="k">if</span> <span class="n">n</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
        <span class="k">elif</span> <span class="n">p1</span> <span class="o">==</span> <span class="n">n</span><span class="p">:</span>
            <span class="c1"># c and d are zero</span>
            <span class="k">return</span> <span class="n">_div</span><span class="p">(</span><span class="n">sqrt</span><span class="p">(</span><span class="n">a</span><span class="p">)</span> <span class="o">-</span> <span class="n">sqrt</span><span class="p">(</span><span class="n">b</span><span class="p">),</span> <span class="n">sqrt</span><span class="p">(</span><span class="n">a</span><span class="p">)</span> <span class="o">+</span> <span class="n">sqrt</span><span class="p">(</span><span class="n">b</span><span class="p">))</span>
        <span class="k">elif</span> <span class="n">p2</span> <span class="o">==</span> <span class="n">n</span><span class="p">:</span>
            <span class="c1"># b and d are zero</span>
            <span class="k">return</span> <span class="n">_div</span><span class="p">(</span><span class="n">sqrt</span><span class="p">(</span><span class="n">a</span><span class="p">)</span> <span class="o">-</span> <span class="n">sqrt</span><span class="p">(</span><span class="n">c</span><span class="p">),</span> <span class="n">sqrt</span><span class="p">(</span><span class="n">a</span><span class="p">)</span> <span class="o">+</span> <span class="n">sqrt</span><span class="p">(</span><span class="n">c</span><span class="p">))</span>
        <span class="k">elif</span> <span class="n">q1</span> <span class="o">==</span> <span class="n">n</span><span class="p">:</span>
            <span class="c1"># a and b are zero</span>
            <span class="k">return</span> <span class="n">_div</span><span class="p">(</span><span class="n">sqrt</span><span class="p">(</span><span class="n">d</span><span class="p">)</span> <span class="o">-</span> <span class="n">sqrt</span><span class="p">(</span><span class="n">c</span><span class="p">),</span> <span class="n">sqrt</span><span class="p">(</span><span class="n">d</span><span class="p">)</span> <span class="o">+</span> <span class="n">sqrt</span><span class="p">(</span><span class="n">c</span><span class="p">))</span>
        <span class="k">elif</span> <span class="n">q2</span> <span class="o">==</span> <span class="n">n</span><span class="p">:</span>
            <span class="c1"># a and c are zero</span>
            <span class="k">return</span> <span class="n">_div</span><span class="p">(</span><span class="n">sqrt</span><span class="p">(</span><span class="n">d</span><span class="p">)</span> <span class="o">-</span> <span class="n">sqrt</span><span class="p">(</span><span class="n">b</span><span class="p">),</span> <span class="n">sqrt</span><span class="p">(</span><span class="n">d</span><span class="p">)</span> <span class="o">+</span> <span class="n">sqrt</span><span class="p">(</span><span class="n">b</span><span class="p">))</span>

        <span class="n">ad</span> <span class="o">=</span> <span class="n">a</span> <span class="o">*</span> <span class="n">d</span>
        <span class="n">bc</span> <span class="o">=</span> <span class="n">b</span> <span class="o">*</span> <span class="n">c</span>

        <span class="k">return</span> <span class="n">_div</span><span class="p">(</span><span class="n">sqrt</span><span class="p">(</span><span class="n">ad</span><span class="p">)</span> <span class="o">-</span> <span class="n">sqrt</span><span class="p">(</span><span class="n">bc</span><span class="p">),</span> <span class="n">sqrt</span><span class="p">(</span><span class="n">ad</span><span class="p">)</span> <span class="o">+</span> <span class="n">sqrt</span><span class="p">(</span><span class="n">bc</span><span class="p">))</span></div>

<div class="viewcode-block" id="ConfusionMatrix2.cole_coeff"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.ConfusionMatrix2.cole_coeff">[docs]</a>    <span class="k">def</span> <span class="nf">cole_coeff</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Cole coefficient</span>

<span class="sd">        This is exactly the same coefficient as *Lewontin&#39;s D&#39;*. It is defined</span>
<span class="sd">        as:</span>

<span class="sd">        .. math::</span>

<span class="sd">            D&#39; = \\frac{cov}{cov_{max}},</span>

<span class="sd">        where :math:`cov_{max}` is the maximum covariance attainable under the</span>
<span class="sd">        given marginal distribution. When :math:`ad \\geq bc`, this coefficient</span>
<span class="sd">        is equivalent to Loevinger&#39;s H.</span>

<span class="sd">        Synonyms: C7, Lewontin&#39;s D&#39;.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        diseq_coeff, loevinger_coeff</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">diseq_coeff</span><span class="p">(</span><span class="n">standardize</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></div>

<div class="viewcode-block" id="ConfusionMatrix2.diseq_coeff"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.ConfusionMatrix2.diseq_coeff">[docs]</a>    <span class="k">def</span> <span class="nf">diseq_coeff</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">standardize</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Linkage disequilibrium</span>

<span class="sd">        .. math::</span>

<span class="sd">            D = \\frac{a}{n} - \\frac{p_1}{n}\\frac{p_2}{n} = \\frac{cov}{n^2}</span>

<span class="sd">        If ``standardize=True``, this measure is further normalized to maximum</span>
<span class="sd">        covariance attainable under given marginal distribution, and the</span>
<span class="sd">        resulting index is called *Lewontin&#39;s D&#39;*.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        cole_coeff</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">cov</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">covar</span><span class="p">()</span>
        <span class="n">n</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">grand_total</span>
        <span class="k">if</span> <span class="n">standardize</span><span class="p">:</span>
            <span class="n">a</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_ccw</span><span class="p">()</span>
            <span class="n">p1</span><span class="p">,</span> <span class="n">q1</span> <span class="o">=</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span><span class="p">,</span> <span class="n">c</span> <span class="o">+</span> <span class="n">d</span>
            <span class="n">p2</span><span class="p">,</span> <span class="n">q2</span> <span class="o">=</span> <span class="n">a</span> <span class="o">+</span> <span class="n">c</span><span class="p">,</span> <span class="n">b</span> <span class="o">+</span> <span class="n">d</span>
            <span class="k">if</span> <span class="n">n</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
            <span class="k">elif</span> <span class="n">a</span> <span class="o">==</span> <span class="n">n</span> <span class="ow">or</span> <span class="n">d</span> <span class="o">==</span> <span class="n">n</span><span class="p">:</span>
                <span class="c1"># only one (diagonal) cell is non-zero</span>
                <span class="k">return</span> <span class="mf">0.5</span>
            <span class="k">elif</span> <span class="n">b</span> <span class="o">==</span> <span class="n">n</span> <span class="ow">or</span> <span class="n">c</span> <span class="o">==</span> <span class="n">n</span><span class="p">:</span>
                <span class="c1"># only one (non-diagonal) cell is non-zero</span>
                <span class="k">return</span> <span class="o">-</span><span class="mf">0.5</span>
            <span class="k">elif</span> <span class="n">cov</span> <span class="o">&gt;</span> <span class="mf">0.0</span><span class="p">:</span>
                <span class="n">cov_max</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">p1</span> <span class="o">*</span> <span class="n">q2</span><span class="p">,</span> <span class="n">p2</span> <span class="o">*</span> <span class="n">q1</span><span class="p">)</span>
                <span class="k">return</span> <span class="n">_div</span><span class="p">(</span><span class="n">cov</span><span class="p">,</span> <span class="n">cov_max</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">cov</span> <span class="o">&lt;</span> <span class="mf">0.0</span><span class="p">:</span>
                <span class="n">cov_max</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">p1</span> <span class="o">*</span> <span class="n">p2</span><span class="p">,</span> <span class="n">q1</span> <span class="o">*</span> <span class="n">q2</span><span class="p">)</span>
                <span class="k">return</span> <span class="n">_div</span><span class="p">(</span><span class="n">cov</span><span class="p">,</span> <span class="n">cov_max</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="mf">0.0</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">_div</span><span class="p">(</span><span class="n">cov</span><span class="p">,</span> <span class="n">n</span> <span class="o">*</span> <span class="n">n</span><span class="p">)</span></div>

<div class="viewcode-block" id="ConfusionMatrix2.covar"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.ConfusionMatrix2.covar">[docs]</a>    <span class="k">def</span> <span class="nf">covar</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Covariance (determinant of a 2x2 matrix)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">a</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_ccw</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">a</span> <span class="o">*</span> <span class="n">d</span> <span class="o">-</span> <span class="n">b</span> <span class="o">*</span> <span class="n">c</span></div>

    <span class="c1"># various silly terminologies follow</span>

    <span class="c1"># information retrieval</span>
    <span class="n">precision</span> <span class="o">=</span> <span class="n">PPV</span>
    <span class="n">recall</span> <span class="o">=</span> <span class="n">TPR</span>
    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">ACC</span>
    <span class="c1"># fallout = FPR</span>

    <span class="c1"># clinical diagnostics</span>
    <span class="n">sensitivity</span> <span class="o">=</span> <span class="n">TPR</span>
    <span class="n">specificity</span> <span class="o">=</span> <span class="n">TNR</span></div>
    <span class="c1"># odds_ratio = DOR</span>
    <span class="c1"># youden_j = informedness</span>

    <span class="c1"># sales/marketing</span>
    <span class="c1"># hit_rate = TPR</span>
    <span class="c1"># miss_rate = FNR</span>

    <span class="c1"># ecology</span>
    <span class="c1"># sm_coeff = ACC</span>
    <span class="c1"># phi_coeff = matthews_corr</span>

    <span class="c1"># meteorology</span>
    <span class="c1"># heidke_skill = kappa</span>
    <span class="c1"># true_skill = informedness</span>


<div class="viewcode-block" id="mutual_info_score"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.mutual_info_score">[docs]</a><span class="k">def</span> <span class="nf">mutual_info_score</span><span class="p">(</span><span class="n">labels_true</span><span class="p">,</span> <span class="n">labels_pred</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Memory-efficient replacement for equivalently named Sklean function</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">ct</span> <span class="o">=</span> <span class="n">ContingencyTable</span><span class="o">.</span><span class="n">from_labels</span><span class="p">(</span><span class="n">labels_true</span><span class="p">,</span> <span class="n">labels_pred</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">ct</span><span class="o">.</span><span class="n">mutual_info_score</span><span class="p">()</span></div>


<div class="viewcode-block" id="homogeneity_completeness_v_measure"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.homogeneity_completeness_v_measure">[docs]</a><span class="k">def</span> <span class="nf">homogeneity_completeness_v_measure</span><span class="p">(</span><span class="n">labels_true</span><span class="p">,</span> <span class="n">labels_pred</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Memory-efficient replacement for equivalently named Scikit-Learn function</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">ct</span> <span class="o">=</span> <span class="n">ContingencyTable</span><span class="o">.</span><span class="n">from_labels</span><span class="p">(</span><span class="n">labels_true</span><span class="p">,</span> <span class="n">labels_pred</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">ct</span><span class="o">.</span><span class="n">entropy_scores</span><span class="p">()</span></div>


<div class="viewcode-block" id="adjusted_rand_score"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.adjusted_rand_score">[docs]</a><span class="k">def</span> <span class="nf">adjusted_rand_score</span><span class="p">(</span><span class="n">labels_true</span><span class="p">,</span> <span class="n">labels_pred</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Rand score (accuracy) corrected for chance</span>

<span class="sd">    This is a memory-efficient replacement for the equivalently named</span>
<span class="sd">    Scikit-Learn function</span>

<span class="sd">    In a supplement to [1]_, the following example is given::</span>

<span class="sd">        &gt;&gt;&gt; classes = [1, 1, 2, 2, 2, 2, 3, 3, 3, 3]</span>
<span class="sd">        &gt;&gt;&gt; clusters = [1, 2, 1, 2, 2, 3, 3, 3, 3, 3]</span>
<span class="sd">        &gt;&gt;&gt; round(adjusted_rand_score(classes, clusters), 3)</span>
<span class="sd">        0.313</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>

<span class="sd">    .. [1] `Yeung, K. Y., &amp; Ruzzo, W. L. (2001). Details of the adjusted Rand</span>
<span class="sd">            index and clustering algorithms, supplement to the paper &quot;An empirical</span>
<span class="sd">            study on principal component analysis for clustering gene expression</span>
<span class="sd">            data&quot;. Bioinformatics, 17(9), 763-774.</span>
<span class="sd">            &lt;http://faculty.washington.edu/kayee/pca/&gt;`_</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">ct</span> <span class="o">=</span> <span class="n">ClusteringMetrics</span><span class="o">.</span><span class="n">from_labels</span><span class="p">(</span><span class="n">labels_true</span><span class="p">,</span> <span class="n">labels_pred</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">ct</span><span class="o">.</span><span class="n">adjusted_rand_index</span><span class="p">()</span></div>


<div class="viewcode-block" id="adjusted_mutual_info_score"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.adjusted_mutual_info_score">[docs]</a><span class="k">def</span> <span class="nf">adjusted_mutual_info_score</span><span class="p">(</span><span class="n">labels_true</span><span class="p">,</span> <span class="n">labels_pred</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Adjusted Mutual Information for two partitions</span>

<span class="sd">    This is a memory-efficient replacement for the equivalently named</span>
<span class="sd">    Scikit-Learn function.</span>

<span class="sd">    Perfect labelings are both homogeneous and complete, hence AMI has the</span>
<span class="sd">    perfect score of one::</span>

<span class="sd">        &gt;&gt;&gt; adjusted_mutual_info_score([0, 0, 1, 1], [0, 0, 1, 1])</span>
<span class="sd">        1.0</span>
<span class="sd">        &gt;&gt;&gt; adjusted_mutual_info_score([0, 0, 1, 1], [1, 1, 0, 0])</span>
<span class="sd">        1.0</span>

<span class="sd">    If classes members are completely split across different clusters, the</span>
<span class="sd">    assignment is utterly incomplete, hence AMI equals zero::</span>

<span class="sd">        &gt;&gt;&gt; adjusted_mutual_info_score([0, 0, 0, 0], [0, 1, 2, 3])</span>
<span class="sd">        0.0</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">ct</span> <span class="o">=</span> <span class="n">ContingencyTable</span><span class="o">.</span><span class="n">from_labels</span><span class="p">(</span><span class="n">labels_true</span><span class="p">,</span> <span class="n">labels_pred</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">ct</span><span class="o">.</span><span class="n">adjusted_mutual_info</span><span class="p">()</span></div>


<div class="viewcode-block" id="product_moment"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.product_moment">[docs]</a><span class="k">def</span> <span class="nf">product_moment</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Return MCC score for a 2x2 contingency table</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">ConfusionMatrix2</span><span class="o">.</span><span class="n">from_ccw</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span><span class="o">.</span><span class="n">matthews_corr</span><span class="p">()</span></div>


<div class="viewcode-block" id="cohen_kappa"><a class="viewcode-back" href="../../clustering_metrics.metrics.html#clustering_metrics.metrics.cohen_kappa">[docs]</a><span class="k">def</span> <span class="nf">cohen_kappa</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Return Cohen&#39;s Kappa for a 2x2 contingency table</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">ConfusionMatrix2</span><span class="o">.</span><span class="n">from_ccw</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span><span class="o">.</span><span class="n">kappa</span><span class="p">()</span></div>
</pre></div>

           </div>
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2015, Eugene Scherba.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../../',
            VERSION:'0.0.2',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true
        };
    </script>
      <script type="text/javascript" src="../../_static/jquery.js"></script>
      <script type="text/javascript" src="../../_static/underscore.js"></script>
      <script type="text/javascript" src="../../_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  
  
    <script type="text/javascript" src="../../_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>